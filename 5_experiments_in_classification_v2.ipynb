{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mr\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    RepeatedKFold,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.custom_transformers\n",
    "import src.custom_transformers as ct\n",
    "\n",
    "%aimport src.ml_helpers\n",
    "from src.ml_helpers import base_pipeline, multi_model_grid_search\n",
    "\n",
    "%aimport src.ml_metrics\n",
    "from src.ml_metrics import (\n",
    "    recall_binary_scorer,\n",
    "    threshold_fpr_score,\n",
    "    threshold_recall_score,\n",
    "    threshold_auc_score,\n",
    ")\n",
    "\n",
    "%aimport src.visualization_helpers\n",
    "from src.visualization_helpers import (\n",
    "    plot_learning_curve,\n",
    "    plot_permutation_importances,\n",
    "    plot_cross_validated_coefs,\n",
    "    show_yb_grid,\n",
    "    plot_grouped_bar_chart,\n",
    "    plot_grouped_histogram,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_colwidth\", 500)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk through machine learning classification experiments on the raw [Lending Club loans data](https://www.lendingclub.com/auth/login?login_url=%2Fstatistics%2Fadditional-statistics%3F). A best-performing model will then be determined and assessed in the context of the business use case for this project.i.e. an conservative investor wanting to use the model developed here to predict which loan applications on the [Lending Club platform](https://www.lendingclub.com/), will not [default](https://en.wikipedia.org/wiki/Default_(finance)), and therefore should be funded by them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User inputs and helper functions, to be used later, are defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "raw_data_file_path = \"data/raw/lending_club_loans.csv\"\n",
    "cloud_storage = \"no\"\n",
    "\n",
    "# From Feature Reduction\n",
    "nan_threshold = 0.5\n",
    "non_useful_cols = [\"url\", \"desc\"]\n",
    "datetime_cols = [\"issue_d\", \"last_pymnt_d\"]\n",
    "cols_one_eighteen = [\n",
    "    \"id\",\n",
    "    \"member_id\",\n",
    "    \"funded_amnt\",\n",
    "    \"funded_amnt_inv\",\n",
    "    \"grade\",\n",
    "    \"sub_grade\",\n",
    "    \"emp_title\",\n",
    "]\n",
    "cols_eighteen_thirtysix = [\n",
    "    \"zip_code\",\n",
    "    \"out_prncp\",\n",
    "    \"out_prncp_inv\",\n",
    "    \"total_pymnt\",\n",
    "    \"total_pymnt_inv\",\n",
    "    \"total_rec_prncp\",\n",
    "]\n",
    "cols_thirtyseven_end = [\n",
    "    \"total_rec_int\",\n",
    "    \"total_rec_late_fee\",\n",
    "    \"recoveries\",\n",
    "    \"collection_recovery_fee\",\n",
    "    \"last_pymnt_amnt\",\n",
    "]\n",
    "loan_status = [\"Fully Paid\", \"Charged Off\"]\n",
    "mapping_dictionary_labels = {\"loan_status\": {\"Fully Paid\": 1, \"Charged Off\": 0}}\n",
    "four_or_less_value_columns = [\"pymnt_plan\"]\n",
    "\n",
    "# From Feature Processing\n",
    "more_than_one_pct_missing_columns = [\"pub_rec_bankruptcies\"]\n",
    "datetime_cols_v2 = [\"last_credit_pull_d\", \"earliest_cr_line\"]\n",
    "high_cardinality_cols = [\"addr_state\"]\n",
    "mapping_dict_emp_length = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0,\n",
    "    }\n",
    "}\n",
    "nominal_columns = [\"home_ownership\", \"verification_status\", \"purpose\", \"term\"]\n",
    "repeated_data_cols = [\"title\"]\n",
    "pct_to_numeric_cols = [\"int_rate\", \"revol_util\"]\n",
    "\n",
    "# From Exploratory Data Analysis 1/2\n",
    "correlated_features = [\n",
    "    # \"total_acc\",\n",
    "    \"installment\",\n",
    "    \"fico_range_low\",\n",
    "    \"fico_range_high\",\n",
    "]\n",
    "look_ahead_features = [\"last_fico_range_low\", \"last_fico_range_high\"]\n",
    "raw_labels = [\"loan_status\"]\n",
    "new_labels = [\"is_default\"]\n",
    "\n",
    "cols_to_show = [\n",
    "    \"preprocessor_type\",\n",
    "    \"resamplers\",\n",
    "    \"clf\",\n",
    "    \"threshold\",\n",
    "    \"params\",\n",
    "    \"mean_test_recall_binary\",\n",
    "    \"mean_test_fpr\",\n",
    "    \"mean_test_auc\",\n",
    "    \"mean_train_recall_binary\",\n",
    "    \"mean_train_fpr\",\n",
    "    \"mean_train_auc\",\n",
    "    \"mean_fit_time\",\n",
    "    \"std_train_recall_binary\",\n",
    "    \"std_test_recall_binary\",\n",
    "    \"std_train_fpr\",\n",
    "    \"std_test_fpr\",\n",
    "    \"mean_score_time\",\n",
    "    \"clf_params\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_threshold = float(nan_threshold)\n",
    "for k in [\"Fully Paid\", \"Charged Off\"]:\n",
    "    mapping_dictionary_labels[\"loan_status\"][k] = int(\n",
    "        mapping_dictionary_labels[\"loan_status\"][k]\n",
    "    )\n",
    "for k in [\n",
    "    \"10+ years\",\n",
    "    \"9 years\",\n",
    "    \"8 years\",\n",
    "    \"7 years\",\n",
    "    \"6 years\",\n",
    "    \"5 years\",\n",
    "    \"4 years\",\n",
    "    \"3 years\",\n",
    "    \"2 years\",\n",
    "    \"1 year\",\n",
    "    \"< 1 year\",\n",
    "    \"n/a\",\n",
    "]:\n",
    "    mapping_dict_emp_length[\"emp_length\"][k] = int(\n",
    "        mapping_dict_emp_length[\"emp_length\"][k]\n",
    "    )\n",
    "\n",
    "# From Exploratory Data Analysis 2/2\n",
    "mapping_dict_new_labels = {\"is_default\": {0: 1, 1: 0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw data from Lending Club is loaded into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloud_storage == \"yes\":\n",
    "    az_storage_container_name = \"myconedesx7\"\n",
    "    conn_str = (\n",
    "        \"DefaultEndpointsProtocol=https;\"\n",
    "        f\"AccountName={os.getenv('AZURE_STORAGE_ACCOUNT')};\"\n",
    "        f\"AccountKey={os.getenv('AZURE_STORAGE_KEY')};\"\n",
    "        f\"EndpointSuffix={os.getenv('ENDPOINT_SUFFIX')}\"\n",
    "    )\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(conn_str=conn_str)\n",
    "\n",
    "    blobstrings = {}\n",
    "    for blob_name in [\"blobedesz38\"]:\n",
    "        blob_client = blob_service_client.get_blob_client(\n",
    "            container=az_storage_container_name, blob=blob_name\n",
    "        )\n",
    "        blobstring = blob_client.download_blob().content_as_text()\n",
    "    df = pd.read_csv(StringIO(blobstring), skiprows=1, low_memory=False)\n",
    "else:\n",
    "    df = pd.read_csv(raw_data_file_path, skiprows=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hold-out set of the raw data will be set aside for model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.33, random_state=4321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data is cleaned, filtered and features are extracted/selected from this processed data in order to run experiments in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1_2_3 = Pipeline(\n",
    "    [\n",
    "        # nan_threshold=0.5, is a float in [0, 1.0] - CAN CHANGE OR KEEP UNCHANGED\n",
    "        (\"nanthresh\", ct.DFNanThresholdColumnDropper(0.5)),\n",
    "        (\"nouse\", ct.DFColumnDropper(non_useful_cols)),\n",
    "        (\"dtime\", ct.DFColumnDropper(datetime_cols)),\n",
    "        (\"c1\", ct.DFColumnDropper(cols_one_eighteen)),\n",
    "        (\"c2\", ct.DFColumnDropper(cols_eighteen_thirtysix)),\n",
    "        (\"c3\", ct.DFColumnDropper(cols_thirtyseven_end)),\n",
    "        (\n",
    "            \"mapstatus\",\n",
    "            ct.DFColumnFilterList(\"loan_status\", loan_status),\n",
    "        ),\n",
    "        (\"colmap\", ct.DFColumnMapper(mapping_dictionary_labels)),\n",
    "        (\"onevals\", ct.DFNonUniqueValColDropper(num_non_unique_vals=1)),\n",
    "        # four_or_less_value_columns=['pymnt_plan'] - 'pymnt_plan' is MOSTLY 'n', EXCLUDE\n",
    "        (\"fourvals\", ct.DFColumnDropper(four_or_less_value_columns)),\n",
    "        # more_than_one_pct_missing_columns = ['pub_rec_bankruptcies']\n",
    "        (\"morethan1pctnan\", ct.DFColumnDropper(more_than_one_pct_missing_columns)),\n",
    "        (\"nan\", ct.DFDropNaN()),\n",
    "        # high_cardinality_cols=['addr_state'] - CAN INCLUDE OR EXCLUDE\n",
    "        (\"hcardcols\", ct.DFColumnDropper(high_cardinality_cols)),\n",
    "        (\"dtimev2\", ct.DFColumnDropper(datetime_cols_v2)),\n",
    "        (\"texttonum\", ct.DFColumnMapper(mapping_dict_emp_length)),\n",
    "        (\"repeats\", ct.DFColumnDropper(repeated_data_cols)),\n",
    "        (\"pctcols\", ct.DFPctNumeric(pct_to_numeric_cols, \"%\")),\n",
    "        (\n",
    "            \"singlecolmap\",\n",
    "            ct.DFSingleColumnMapper(\"loan_status\", mapping_dict_new_labels),\n",
    "        ),\n",
    "        (\"dtype\", ct.DFSimpleDtypeChanger(new_labels, \"int\")),\n",
    "        # n_std is an integer - CAN CHANGE OR KEEP UNCHANGED\n",
    "        (\"stdfilter\", ct.DFColumnStdFilter(\"annual_inc\", 3)),\n",
    "        # correlated_features=['total_acc','installment','fico_range_low','fico_range_high'] EXCLUDE\n",
    "        (\"corr\", ct.DFColumnDropper(correlated_features)),\n",
    "        (\"lookahead\", ct.DFColumnDropper(look_ahead_features)),\n",
    "        (\"label\", ct.DFColumnDropper(raw_labels)),\n",
    "        # requires (\"corr\", ...) to be removed; threshold=1, ideally chosen from dendogram\n",
    "        # (\"clusterselect\", ct.DFHierarchicalClusterSpearmanRank(threshold=1)),\n",
    "    ]\n",
    ")\n",
    "df_pipe_transformed_train = pipe_1_2_3.fit_transform(df_train)\n",
    "df_pipe_transformed_test = pipe_1_2_3.transform(df_test)\n",
    "print(df_pipe_transformed_train.shape)\n",
    "print(df_pipe_transformed_test.shape)\n",
    "display(df_pipe_transformed_train.head(2))\n",
    "display(df_pipe_transformed_test.head(2))\n",
    "display(df_pipe_transformed_train[\"is_default\"].squeeze().value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features and class labels from processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features and labels are now extracted from the processed training and testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_pipe_transformed_train.drop(labels=new_labels, axis=1)\n",
    "y_train = df_pipe_transformed_train[new_labels].astype(int).squeeze()\n",
    "X_test = df_pipe_transformed_test.drop(labels=new_labels, axis=1)\n",
    "y_test = df_pipe_transformed_test[new_labels].astype(int).squeeze()\n",
    "display(X_train.head(2))\n",
    "display(X_test.head(2))\n",
    "display(y_train.to_frame().head(2))\n",
    "display(y_test.to_frame().head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble components for `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline inputs and other components required for hyperparameter optimization using `GridSearchCV` are extracted here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists of features by type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of numerical and categorical features is extracted from the processed data\n",
    "- numerical features are those with a datatype of `float`\n",
    "- categorical features are those that do not have a datatype of `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    c\n",
    "    for c in list(X_train.select_dtypes(exclude=\"object\"))\n",
    "    if c not in new_labels + [\"emp_length\"]\n",
    "]\n",
    "nominal_columns = list(X_train.select_dtypes(include=\"object\")) + [\"emp_length\"]\n",
    "try:\n",
    "    assert set(numerical_columns + nominal_columns) == set(list(X_train)) - set(\n",
    "        new_labels\n",
    "    )\n",
    "    print(\"Columns from training data match feature lists\")\n",
    "except AssertionError as e:\n",
    "    print(\"Some columns from training data are missing from feature lists\")\n",
    "print(\"Categoricals:\\n-\" + \"\\n-\".join(nominal_columns))\n",
    "print(\"Numericals:\\n-\" + \"\\n-\".join(numerical_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, feature transformations to be applied to all numerical columns are defined. With or without transformations, all numerical features will be normalized. All categorical features will be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_transformers = {\n",
    "    c: Pipeline(\n",
    "        steps=[\n",
    "            (\"trans\", ct.DFPowerTransformer(\"yeo-johnson\")),\n",
    "            (\"ss\", ct.DFStandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "    for c in numerical_columns\n",
    "}\n",
    "preprocessors = {\n",
    "    \"no_trans\": ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\n",
    "                \"nums\",\n",
    "                Pipeline(steps=[(\"trans\", StandardScaler())]),\n",
    "                numerical_columns,\n",
    "            )\n",
    "        ]\n",
    "        + [(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), nominal_columns)],\n",
    "        remainder=\"passthrough\",\n",
    "    ),\n",
    "    \"trans\": ColumnTransformer(\n",
    "        transformers=[(k, v, [k]) for k, v in col_transformers.items()]\n",
    "        + [(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), nominal_columns)],\n",
    "        remainder=\"passthrough\",\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers and hyper-parameters for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models to be compared, discrimination threshold(s) (to be applied to all listed models), and dictionaries of model hyper-parameters for tuning, are defined below\n",
    "- for hyper-parameter dictionaries containing cost-function weights, for manual specification of the penalties used in the algorithm's cost function, the larger penalty should be assigned to the minority class (see [**Lesson 07. Cost-Sensitive Algorithms**](https://machinelearningmastery.com/imbalanced-classification-with-python-7-day-mini-course/))\n",
    "  - here, this is for the positive class where `is_default`==1, and is explicitly shown below through the class-balance of the labels from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_list = [\n",
    "    LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=500),\n",
    "]\n",
    "parameters = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"C\": [1.0],\n",
    "        \"class_weight\": [\n",
    "            \"balanced\",\n",
    "            {0: 1, 1: 5},\n",
    "            {0: 1, 1: 6},\n",
    "            {0: 1, 1: 8},\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"preprocessor\", preprocessors[\"no_trans\"]), (\"clf\", clf_list[0])])\n",
    "params_dict = {\n",
    "    f\"clf__{k}\": v for k, v in parameters[type(clf_list[0]).__name__].items()\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_binary_scorer(y_true, y_pred):\n",
    "    roc_auc_binary_score = roc_auc_score(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        average=\"weighted\",\n",
    "        sample_weight=compute_sample_weight(class_weight=\"balanced\", y=y_true),\n",
    "    )\n",
    "    return roc_auc_binary_score\n",
    "\n",
    "\n",
    "def recall_binary_scorer(y_true, y_pred):\n",
    "    recall_binary_score = recall_score(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        average=\"binary\",\n",
    "        sample_weight=compute_sample_weight(class_weight=\"balanced\", y=y_true),\n",
    "    )\n",
    "    return recall_binary_score\n",
    "\n",
    "\n",
    "def false_positive_rate_scorer(y_true, y_pred):\n",
    "    tn = y_pred[(y_pred == 0) & (y_true == 0)].shape[0]\n",
    "    fp = y_pred[(y_pred == 1) & (y_true == 0)].shape[0]\n",
    "    fpr = fp / (fp + tn)\n",
    "    return -fpr\n",
    "\n",
    "\n",
    "def threshold_roc_auc_score(ground_truth, predictions, threshold=0.5):\n",
    "    predicted = (predictions >= threshold).astype(\"int\")\n",
    "    roc_auc = roc_auc_binary_scorer(ground_truth, predicted)\n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "def threshold_recall_score(ground_truth, predictions, threshold=0.5):\n",
    "    predicted = (predictions >= threshold).astype(\"int\")\n",
    "    recall = recall_binary_scorer(ground_truth, predicted)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def threshold_fpr_score(ground_truth, predictions, threshold=0.5):\n",
    "    predicted = (predictions >= threshold).astype(\"int\")\n",
    "    fpr = false_positive_rate_scorer(ground_truth, predicted)\n",
    "    return fpr\n",
    "\n",
    "\n",
    "def pr_auc_score(ground_truth, y_probs):\n",
    "    precision, recall, _ = mr.precision_recall_curve(ground_truth, y_probs)\n",
    "    pr_auc_score = mr.auc(recall, precision)\n",
    "    return pr_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_scorers = {\n",
    "    \"recall_binary\": make_scorer(\n",
    "        threshold_recall_score,\n",
    "        greater_is_better=True,\n",
    "        needs_proba=True,\n",
    "        threshold=0.5,\n",
    "    ),\n",
    "    \"fpr\": make_scorer(\n",
    "        threshold_fpr_score,\n",
    "        greater_is_better=False,\n",
    "        needs_proba=True,\n",
    "        threshold=0.5,\n",
    "    ),\n",
    "    \"roc_auc_binary\": make_scorer(\n",
    "        threshold_roc_auc_score,\n",
    "        greater_is_better=True,\n",
    "        needs_proba=True,\n",
    "        threshold=0.5,\n",
    "    ),\n",
    "    \"pr_auc\": make_scorer(\n",
    "        pr_auc_score,\n",
    "        greater_is_better=True,\n",
    "        needs_proba=True,\n",
    "    ),\n",
    "}\n",
    "cols_to_show = [\n",
    "    # \"preprocessor_type\",\n",
    "    # \"resamplers\",\n",
    "    \"clf\",\n",
    "    \"params\",\n",
    "    \"mean_test_recall_binary\",\n",
    "    \"mean_test_fpr\",\n",
    "    \"mean_test_roc_auc_binary\",\n",
    "    \"mean_test_pr_auc\",\n",
    "    \"mean_train_recall_binary\",\n",
    "    \"mean_train_fpr\",\n",
    "    \"mean_train_roc_auc_binary\",\n",
    "    \"mean_train_pr_auc\",\n",
    "    \"mean_fit_time\",\n",
    "    \"std_train_recall_binary\",\n",
    "    \"std_test_recall_binary\",\n",
    "    \"std_train_fpr\",\n",
    "    \"std_test_fpr\",\n",
    "    \"std_train_roc_auc_binary\",\n",
    "    \"std_test_roc_auc_binary\",\n",
    "    \"std_train_pr_auc\",\n",
    "    \"std_test_pr_auc\",\n",
    "    \"mean_score_time\",\n",
    "    \"clf_params\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=params_dict,\n",
    "    cv=cv,\n",
    "    scoring=multi_scorers,\n",
    "    refit=\"recall_binary\",\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "gs.fit(X_train, y_train)\n",
    "resamplers = list(set(list(pipe.named_steps.keys())) - set([\"preprocessor\", \"clf\"]))\n",
    "# print(resamplers)\n",
    "df_gs = (\n",
    "    pd.DataFrame(gs.cv_results_)\n",
    "    .assign(preprocessor_type=preprocessors[\"no_trans\"])\n",
    "    .assign(resamplers=\",\".join(resamplers))\n",
    "    .assign(clf_params=type(clf_list[0]).__name__ + \"_(\" + str(params_dict) + \"\" + \")\")\n",
    ")\n",
    "df_gs.insert(0, \"clf\", type(clf_list[0]).__name__)\n",
    "display(df_gs[cols_to_show])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
