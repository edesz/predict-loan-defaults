{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mr\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RepeatedKFold,\n",
    "    ShuffleSplit,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.altair_helpers\n",
    "from src.altair_helpers import (\n",
    "    plot_altair_grid,\n",
    "    alt_plot_metric_based_threshold_tuning_plots,\n",
    ")\n",
    "\n",
    "%aimport src.business_helpers\n",
    "from src.business_helpers import int_income_calculator\n",
    "\n",
    "%aimport src.custom_learning_curve_helpers\n",
    "from src.custom_learning_curve_helpers import learning_curve, manual_learning_curve\n",
    "\n",
    "%aimport src.custom_permutation_importance_helpers\n",
    "from src.custom_permutation_importance_helpers import manual_plot_permutation_importance\n",
    "\n",
    "%aimport src.custom_threshold_tuning_plotting_helpers\n",
    "from src.custom_threshold_tuning_plotting_helpers import (\n",
    "    plot_cost_function_based_threshold_tuning_plots,\n",
    "    plot_metric_based_threshold_tuning_plots,\n",
    ")\n",
    "\n",
    "%aimport src.custom_transformers\n",
    "import src.custom_transformers as ct\n",
    "\n",
    "%aimport src.custom_returns_plotter\n",
    "from src.custom_returns_plotter import plot_returns\n",
    "\n",
    "%aimport src.ml_helpers_v2\n",
    "from src.ml_helpers_v2 import get_best_pipes, gridsearch\n",
    "\n",
    "%aimport src.ml_metrics_v2\n",
    "from src.ml_metrics_v2 import (\n",
    "    threshold_roc_auc_score,\n",
    "    threshold_fpr_score,\n",
    "    threshold_f2_score,\n",
    "    threshold_recall_score,\n",
    "    pr_auc_score,\n",
    "    get_scores,\n",
    "    get_eval_metrics,\n",
    ")\n",
    "\n",
    "%aimport src.threshold_tuning_helpers\n",
    "from src.threshold_tuning_helpers import (\n",
    "    get_components_of_returns,\n",
    "    threshold_tuning_reshaping,\n",
    ")\n",
    "\n",
    "%aimport src.visualization_helpers\n",
    "from src.visualization_helpers import (\n",
    "    plot_learning_curve,\n",
    "    plot_permutation_importances,\n",
    "    plot_grouped_bar_chart,\n",
    "    plot_grouped_histogram,\n",
    "    plot_pr_roc_curves,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_colwidth\", 500)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk through machine learning classification experiments on the raw [Lending Club loans data](https://www.lendingclub.com/auth/login?login_url=%2Fstatistics%2Fadditional-statistics%3F). A best-performing model will then be determined and assessed in the context of the business use case for this project.i.e. an conservative investor wanting to use the model developed here to predict which loan applications on the [Lending Club platform](https://www.lendingclub.com/), will not [default](https://en.wikipedia.org/wiki/Default_(finance)), and therefore should be funded by them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User inputs and helper functions, to be used later, are defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "raw_data_file_path = \"data/raw/lending_club_loans.csv\"\n",
    "cloud_storage = \"no\"\n",
    "\n",
    "# From Feature Reduction\n",
    "nan_threshold = 0.5\n",
    "non_useful_cols = [\"url\", \"desc\"]\n",
    "datetime_cols = [\"issue_d\", \"last_pymnt_d\"]\n",
    "cols_one_eighteen = [\n",
    "    \"id\",\n",
    "    \"member_id\",\n",
    "    \"funded_amnt\",\n",
    "    \"funded_amnt_inv\",\n",
    "    \"grade\",\n",
    "    \"sub_grade\",\n",
    "    \"emp_title\",\n",
    "]\n",
    "cols_eighteen_thirtysix = [\n",
    "    \"zip_code\",\n",
    "    \"out_prncp\",\n",
    "    \"out_prncp_inv\",\n",
    "    \"total_pymnt\",\n",
    "    \"total_pymnt_inv\",\n",
    "    \"total_rec_prncp\",\n",
    "]\n",
    "cols_thirtyseven_end = [\n",
    "    \"total_rec_int\",\n",
    "    \"total_rec_late_fee\",\n",
    "    \"recoveries\",\n",
    "    \"collection_recovery_fee\",\n",
    "    \"last_pymnt_amnt\",\n",
    "]\n",
    "loan_status = [\"Fully Paid\", \"Charged Off\"]\n",
    "mapping_dictionary_labels = {\"loan_status\": {\"Fully Paid\": 1, \"Charged Off\": 0}}\n",
    "four_or_less_value_columns = [\"pymnt_plan\"]\n",
    "\n",
    "# From Feature Processing\n",
    "more_than_one_pct_missing_columns = [\"pub_rec_bankruptcies\"]\n",
    "datetime_cols_v2 = [\"last_credit_pull_d\", \"earliest_cr_line\"]\n",
    "high_cardinality_cols = [\"addr_state\"]\n",
    "mapping_dict_emp_length = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0,\n",
    "    }\n",
    "}\n",
    "nominal_columns = [\"home_ownership\", \"verification_status\", \"purpose\", \"term\"]\n",
    "repeated_data_cols = [\"title\"]\n",
    "pct_to_numeric_cols = [\"int_rate\", \"revol_util\"]\n",
    "\n",
    "# From Exploratory Data Analysis 1/2\n",
    "correlated_features = [\n",
    "    # \"total_acc\",\n",
    "    \"installment\",\n",
    "    \"fico_range_low\",\n",
    "    \"fico_range_high\",\n",
    "]\n",
    "look_ahead_features = [\"last_fico_range_low\", \"last_fico_range_high\"]\n",
    "raw_labels = [\"loan_status\"]\n",
    "new_labels = [\"is_default\"]\n",
    "\n",
    "cols_to_show = [\n",
    "    \"preprocessor_type\",\n",
    "    \"resamplers\",\n",
    "    \"threshold\",\n",
    "    \"params\",\n",
    "    \"mean_test_recall_binary\",\n",
    "    \"mean_test_fpr\",\n",
    "    \"mean_test_auc\",\n",
    "    \"mean_train_recall_binary\",\n",
    "    \"mean_train_fpr\",\n",
    "    \"mean_train_auc\",\n",
    "    \"mean_fit_time\",\n",
    "    \"std_train_recall_binary\",\n",
    "    \"std_test_recall_binary\",\n",
    "    \"std_train_fpr\",\n",
    "    \"std_test_fpr\",\n",
    "    \"mean_score_time\",\n",
    "    \"clf_params\",\n",
    "]\n",
    "\n",
    "thresholds_list = np.arange(0.01, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_threshold = float(nan_threshold)\n",
    "for k in [\"Fully Paid\", \"Charged Off\"]:\n",
    "    mapping_dictionary_labels[\"loan_status\"][k] = int(\n",
    "        mapping_dictionary_labels[\"loan_status\"][k]\n",
    "    )\n",
    "for k in [\n",
    "    \"10+ years\",\n",
    "    \"9 years\",\n",
    "    \"8 years\",\n",
    "    \"7 years\",\n",
    "    \"6 years\",\n",
    "    \"5 years\",\n",
    "    \"4 years\",\n",
    "    \"3 years\",\n",
    "    \"2 years\",\n",
    "    \"1 year\",\n",
    "    \"< 1 year\",\n",
    "    \"n/a\",\n",
    "]:\n",
    "    mapping_dict_emp_length[\"emp_length\"][k] = int(\n",
    "        mapping_dict_emp_length[\"emp_length\"][k]\n",
    "    )\n",
    "\n",
    "# From Exploratory Data Analysis 2/2\n",
    "mapping_dict_new_labels = {\"is_default\": {0: 1, 1: 0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_scorers = {\n",
    "    \"recall_binary\": mr.make_scorer(\n",
    "        threshold_recall_score,\n",
    "        greater_is_better=True,\n",
    "        needs_proba=True,\n",
    "        threshold=0.5,\n",
    "    ),\n",
    "    \"fpr\": mr.make_scorer(\n",
    "        threshold_fpr_score,\n",
    "        greater_is_better=False,\n",
    "        needs_proba=True,\n",
    "        threshold=0.5,\n",
    "    ),\n",
    "    \"f2\": mr.make_scorer(\n",
    "        threshold_f2_score,\n",
    "        greater_is_better=True,\n",
    "        needs_proba=True,\n",
    "        threshold=0.5,\n",
    "    ),\n",
    "    \"roc_auc_binary\": mr.make_scorer(\n",
    "        threshold_roc_auc_score,\n",
    "        greater_is_better=True,\n",
    "        needs_proba=True,\n",
    "        threshold=0.5,\n",
    "    ),\n",
    "    \"pr_auc\": mr.make_scorer(\n",
    "        pr_auc_score,\n",
    "        greater_is_better=True,\n",
    "        needs_proba=True,\n",
    "    ),\n",
    "}\n",
    "cols_to_show = [\n",
    "    \"mean_test_recall_binary\",\n",
    "    \"mean_test_fpr\",\n",
    "    \"mean_test_roc_auc_binary\",\n",
    "    \"mean_test_pr_auc\",\n",
    "    \"mean_train_recall_binary\",\n",
    "    \"mean_train_fpr\",\n",
    "    \"mean_train_roc_auc_binary\",\n",
    "    \"mean_train_pr_auc\",\n",
    "    \"mean_fit_time\",\n",
    "    \"std_train_recall_binary\",\n",
    "    \"std_test_recall_binary\",\n",
    "    \"std_train_fpr\",\n",
    "    \"std_test_fpr\",\n",
    "    \"std_train_roc_auc_binary\",\n",
    "    \"std_test_roc_auc_binary\",\n",
    "    \"std_train_pr_auc\",\n",
    "    \"std_test_pr_auc\",\n",
    "    \"mean_score_time\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw data from Lending Club is loaded into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloud_storage == \"yes\":\n",
    "    az_storage_container_name = \"myconedesx7\"\n",
    "    conn_str = (\n",
    "        \"DefaultEndpointsProtocol=https;\"\n",
    "        f\"AccountName={os.getenv('AZURE_STORAGE_ACCOUNT')};\"\n",
    "        f\"AccountKey={os.getenv('AZURE_STORAGE_KEY')};\"\n",
    "        f\"EndpointSuffix={os.getenv('ENDPOINT_SUFFIX')}\"\n",
    "    )\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(conn_str=conn_str)\n",
    "\n",
    "    blobstrings = {}\n",
    "    for blob_name in [\"blobedesz38\"]:\n",
    "        blob_client = blob_service_client.get_blob_client(\n",
    "            container=az_storage_container_name, blob=blob_name\n",
    "        )\n",
    "        blobstring = blob_client.download_blob().content_as_text()\n",
    "    df = pd.read_csv(StringIO(blobstring), skiprows=1, low_memory=False)\n",
    "else:\n",
    "    df = pd.read_csv(raw_data_file_path, skiprows=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hold-out set of the raw data will be set aside for model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val, df_test = train_test_split(df, test_size=0.33, random_state=4321)\n",
    "df_train, df_val = train_test_split(df_train_val, test_size=0.33, random_state=4321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data is cleaned, filtered and features are extracted/selected from this processed data in order to run experiments in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1_2_3 = Pipeline(\n",
    "    [\n",
    "        # nan_threshold=0.5, is a float in [0, 1.0] - CAN CHANGE OR KEEP UNCHANGED\n",
    "        (\"nanthresh\", ct.DFNanThresholdColumnDropper(0.5)),\n",
    "        (\"nouse\", ct.DFColumnDropper(non_useful_cols)),\n",
    "        (\"dtime\", ct.DFColumnDropper(datetime_cols)),\n",
    "        (\"c1\", ct.DFColumnDropper(cols_one_eighteen)),\n",
    "        (\"c2\", ct.DFColumnDropper(cols_eighteen_thirtysix)),\n",
    "        (\"c3\", ct.DFColumnDropper(cols_thirtyseven_end)),\n",
    "        (\n",
    "            \"mapstatus\",\n",
    "            ct.DFColumnFilterList(\"loan_status\", loan_status),\n",
    "        ),\n",
    "        (\"colmap\", ct.DFColumnMapper(mapping_dictionary_labels)),\n",
    "        (\"onevals\", ct.DFNonUniqueValColDropper(num_non_unique_vals=1)),\n",
    "        # four_or_less_value_columns=['pymnt_plan'] - 'pymnt_plan' is MOSTLY 'n', EXCLUDE\n",
    "        (\"fourvals\", ct.DFColumnDropper(four_or_less_value_columns)),\n",
    "        # more_than_one_pct_missing_columns = ['pub_rec_bankruptcies']\n",
    "        (\"morethan1pctnan\", ct.DFColumnDropper(more_than_one_pct_missing_columns)),\n",
    "        (\"nan\", ct.DFDropNaN()),\n",
    "        # high_cardinality_cols=['addr_state'] - CAN INCLUDE OR EXCLUDE\n",
    "        (\"hcardcols\", ct.DFColumnDropper(high_cardinality_cols)),\n",
    "        (\"dtimev2\", ct.DFColumnDropper(datetime_cols_v2)),\n",
    "        (\"texttonum\", ct.DFColumnMapper(mapping_dict_emp_length)),\n",
    "        (\"repeats\", ct.DFColumnDropper(repeated_data_cols)),\n",
    "        (\"pctcols\", ct.DFPctNumeric(pct_to_numeric_cols, \"%\")),\n",
    "        (\n",
    "            \"singlecolmap\",\n",
    "            ct.DFSingleColumnMapper(\"loan_status\", mapping_dict_new_labels),\n",
    "        ),\n",
    "        (\"dtype\", ct.DFSimpleDtypeChanger(new_labels, \"int\")),\n",
    "        # n_std is an integer - CAN CHANGE OR KEEP UNCHANGED\n",
    "        (\"stdfilter\", ct.DFColumnStdFilter(\"annual_inc\", 3)),\n",
    "        # correlated_features=['total_acc','installment','fico_range_low','fico_range_high'] EXCLUDE\n",
    "        (\"corr\", ct.DFColumnDropper(correlated_features)),\n",
    "        (\"lookahead\", ct.DFColumnDropper(look_ahead_features)),\n",
    "        (\"label\", ct.DFColumnDropper(raw_labels)),\n",
    "        # requires (\"corr\", ...) to be removed; threshold=1, ideally chosen from dendogram\n",
    "        # (\"clusterselect\", ct.DFHierarchicalClusterSpearmanRank(threshold=1)),\n",
    "    ]\n",
    ")\n",
    "df_pipe_transformed_train = pipe_1_2_3.fit_transform(df_train)\n",
    "df_pipe_transformed_val = pipe_1_2_3.transform(df_val)\n",
    "df_pipe_transformed_train_val = pipe_1_2_3.transform(df_train_val)\n",
    "df_pipe_transformed_test = pipe_1_2_3.transform(df_test)\n",
    "print(df_pipe_transformed_train.shape)\n",
    "print(df_pipe_transformed_val.shape)\n",
    "print(df_pipe_transformed_train_val.shape)\n",
    "print(df_pipe_transformed_test.shape)\n",
    "display(df_pipe_transformed_train.head(2))\n",
    "display(df_pipe_transformed_val.head(2))\n",
    "display(df_pipe_transformed_train_val.head(2))\n",
    "display(df_pipe_transformed_test.head(2))\n",
    "display(df_pipe_transformed_train[\"is_default\"].squeeze().value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features and class labels from processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features and labels are now extracted from the processed training and testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_pipe_transformed_train.drop(labels=new_labels, axis=1)\n",
    "y_train = df_pipe_transformed_train[new_labels].astype(int).squeeze()\n",
    "X_val = df_pipe_transformed_val.drop(labels=new_labels, axis=1)\n",
    "y_val = df_pipe_transformed_val[new_labels].astype(int).squeeze()\n",
    "X_train_val = df_pipe_transformed_test.drop(labels=new_labels, axis=1)\n",
    "y_train_val = df_pipe_transformed_test[new_labels].astype(int).squeeze()\n",
    "X_test = df_pipe_transformed_test.drop(labels=new_labels, axis=1)\n",
    "y_test = df_pipe_transformed_test[new_labels].astype(int).squeeze()\n",
    "display(X_train.head(2))\n",
    "display(X_val.head(2))\n",
    "display(X_test.head(2))\n",
    "display(X_train_val.head(2))\n",
    "display(y_train.to_frame().head(2))\n",
    "display(y_val.to_frame().head(2))\n",
    "display(y_test.to_frame().head(2))\n",
    "display(y_train_val.to_frame().head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble components for `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline inputs and other components required for hyperparameter optimization using `GridSearchCV` are extracted here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists of features by type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of numerical and categorical features is extracted from the processed data\n",
    "- numerical features are those with a datatype of `float`\n",
    "- categorical features are those that do not have a datatype of `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    c\n",
    "    for c in list(X_train.select_dtypes(exclude=\"object\"))\n",
    "    if c not in new_labels + [\"emp_length\"]\n",
    "]\n",
    "nominal_columns = list(X_train.select_dtypes(include=\"object\")) + [\"emp_length\"]\n",
    "try:\n",
    "    assert set(numerical_columns + nominal_columns) == set(list(X_train)) - set(\n",
    "        new_labels\n",
    "    )\n",
    "    print(\"Columns from training data match feature lists\")\n",
    "except AssertionError as e:\n",
    "    print(\"Some columns from training data are missing from feature lists\")\n",
    "print(\"Categoricals:\\n-\" + \"\\n-\".join(nominal_columns))\n",
    "print(\"Numericals:\\n-\" + \"\\n-\".join(numerical_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, feature transformations to be applied to all numerical columns are defined. With or without transformations, all numerical features will be normalized. All categorical features will be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_transformers = {\n",
    "    c: Pipeline(\n",
    "        steps=[\n",
    "            (\"trans\", ct.DFPowerTransformer(\"yeo-johnson\")),\n",
    "            (\"ss\", ct.DFStandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "    for c in numerical_columns\n",
    "}\n",
    "preprocessors = {\n",
    "    \"no_trans\": ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\n",
    "                \"nums\",\n",
    "                Pipeline(steps=[(\"trans\", StandardScaler())]),\n",
    "                numerical_columns,\n",
    "            )\n",
    "        ]\n",
    "        + [(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), nominal_columns)],\n",
    "        remainder=\"passthrough\",\n",
    "    ),\n",
    "    \"trans\": ColumnTransformer(\n",
    "        transformers=[(k, v, [k]) for k, v in col_transformers.items()]\n",
    "        + [(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), nominal_columns)],\n",
    "        remainder=\"passthrough\",\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers and hyper-parameters for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models to be compared, discrimination threshold(s) (to be applied to all listed models), and dictionaries of model hyper-parameters for tuning, are defined below\n",
    "- for hyper-parameter dictionaries containing cost-function weights, for manual specification of the penalties used in the algorithm's cost function, the larger penalty should be assigned to the minority class (see [**Lesson 07. Cost-Sensitive Algorithms**](https://machinelearningmastery.com/imbalanced-classification-with-python-7-day-mini-course/))\n",
    "  - here, this is for the positive class where `is_default`==1, and is explicitly shown below through the class-balance of the labels from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = np.unique(y_train, return_counts=True)[1]\n",
    "minority_weight = vc[0] / vc[1]\n",
    "parameters = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"C\": [1.0],\n",
    "        \"class_weight\": [\n",
    "            \"balanced\",\n",
    "            None,\n",
    "            {0: 1, 1: 1},\n",
    "            {0: 1, 1: minority_weight},\n",
    "            {0: 1, 1: 8},\n",
    "        ],\n",
    "    },\n",
    "    \"DummyClassifier\": {\"strategy\": [\"stratified\"]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "df_gs = gridsearch(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    parameters,\n",
    "    preprocessors[\"no_trans\"],\n",
    "    cv,\n",
    "    multi_scorers,\n",
    "    threshold=0.5,\n",
    ")\n",
    "param_cols = df_gs.columns[\n",
    "    df_gs.columns.to_series().str.contains(\"param_\")\n",
    "].tolist()\n",
    "display(df_gs[[\"clf\"]+param_cols+cols_to_show])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cfg_idx = 0\n",
    "best_dummy_cfg_idx = 5\n",
    "best_pipe, best_dummy_pipe = get_best_pipes(\n",
    "    best_cfg_idx, best_dummy_cfg_idx, df_gs, preprocessors[\"no_trans\"], param_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, confs = get_components_of_returns(X_val)\n",
    "confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_pipe.fit(X_train, y_train)\n",
    "best_dummy_pipe.fit(X_train, y_train)\n",
    "y_probs_val = best_pipe.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "(\n",
    "    df_threshold_tuning_scores,\n",
    "    df_all_threshold_tuning_scores\n",
    ") = plot_metric_based_threshold_tuning_plots(\n",
    "    y_val,\n",
    "    y_probs_val,\n",
    "    thresholds_list,\n",
    "    f2_beta=2,\n",
    "    legend_position=(1.01, 1),\n",
    "    show_best_t_by_f1=False,\n",
    "    show_plot=False,\n",
    "    fig_size=(8, 4),\n",
    ")\n",
    "display(df_threshold_tuning_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_plot_metric_based_threshold_tuning_plots(\n",
    "    df_all_threshold_tuning_scores,\n",
    "    ptitle_offset=-5,\n",
    "    legend_offset=5,\n",
    "    figsize=(450, 300),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. this is the sum of `n` [monthly returns](https://www.vertex42.com/ExcelArticles/amortization-calculation.html) that a prospective funder of the loan would expect to receive if the loan is paid off on time\n",
    "2. Why divide by `len(y_test)`?\n",
    "   - If every loan had these r,n,p, anbd other factos were consisnt, and taking the model's predictive power into account, then the average return would be given by `ds /= len(y_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_returns_t_tuned, df_returns_t_tuning_full = plot_cost_function_based_threshold_tuning_plots(best_pipe, best_dummy_pipe, X_val, y_val, confs, thresholds_list)\n",
    "display(df_returns_t_tuned)\n",
    "display(df_returns_t_tuning_full.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_t = 0.75\n",
    "df_returns_best_t, _ = plot_cost_function_based_threshold_tuning_plots(best_pipe, best_dummy_pipe, X_val, y_val, confs, [best_t])\n",
    "df_returns_best_t = threshold_tuning_reshaping(df_returns_best_t)\n",
    "display(df_returns_best_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_returns(\n",
    "    df_returns_best_t.sort_values(by=[\"clf\", \"return\"], ascending=[False, False]),\n",
    "    ptitle=\"Comparison of Theoretical (if paid on time) and Predicted* Returns\",\n",
    "    annotation_text=f\"*using optimal discrimination threshold ({best_t})\",\n",
    "    axis_tick_fontsize=12,\n",
    "    annotation_text_fontsize=10,\n",
    "    annotation_loc=(0.99, 0.01),\n",
    "    fig_size=(8, 4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. It is average becuase the model will not alwyas predict that you should fund such a loan. There are times when it incorrectly predicts that the loan should not be funded - in such a scenario, prospective return is lost. If you used an independent methd of predicting loans to fund, and the loan was paid off on time, then the return you earn would be the theoretical return from the above graph/table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_pipe.fit(X_train_val, y_train_val)\n",
    "best_dummy_pipe.fit(X_train_val, y_train_val)\n",
    "y_probs_test = best_pipe.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, confs_test = get_components_of_returns(X_train_val)\n",
    "confs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_returns_best_t_test, _ = plot_cost_function_based_threshold_tuning_plots(best_pipe, best_dummy_pipe, X_test, y_test, confs_test, [best_t])\n",
    "df_returns_best_t_test = threshold_tuning_reshaping(df_returns_best_t_test)\n",
    "display(df_returns_best_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_returns(\n",
    "    df_returns_best_t_test.sort_values(by=[\"clf\", \"return\"], ascending=[False, False]),\n",
    "    ptitle=\"Comparison of Theoretical (if paid on time) and Predicted* Returns\",\n",
    "    annotation_text=f\"*using optimal discrimination threshold ({best_t})\",\n",
    "    axis_tick_fontsize=12,\n",
    "    annotation_text_fontsize=10,\n",
    "    annotation_loc=(0.99, 0.01),\n",
    "    fig_size=(8, 4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Diagnostic metrics and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores, y_pred_test_selected_threshold = get_eval_metrics(\n",
    "    y_test.to_numpy(), y_probs_test, split=\"test\", threshold=best_t, beta=2\n",
    ")\n",
    "display(df_scores.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = (\n",
    "    pd.DataFrame(\n",
    "        mr.confusion_matrix(\n",
    "            y_test,\n",
    "            y_pred_test_selected_threshold,\n",
    "            labels=np.sort(np.unique(y_train_val)),\n",
    "        ),\n",
    "        index=np.sort(np.unique(y_train_val)),\n",
    "        columns=np.sort(np.unique(y_train_val)),\n",
    "    )\n",
    "    .rename_axis(\"actual\", axis=\"columns\")\n",
    "    .rename_axis(\"predicted\", axis=\"rows\")\n",
    ")\n",
    "df_cr = pd.DataFrame(\n",
    "    mr.classification_report(\n",
    "        y_test,\n",
    "        y_pred_test_selected_threshold,\n",
    "        target_names=np.sort(np.unique(y_train_val)),\n",
    "        output_dict=True,\n",
    "    )\n",
    ").T\n",
    "plot_altair_grid(\n",
    "    df_cm,\n",
    "    df_cr,\n",
    "    ptitle_offset=-5,\n",
    "    cpe_figsize=(150, 300),\n",
    "    cm_figsize=(150, 300),\n",
    "    cr_figsize=[(250, 300), (100, 300)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. The poor performance is not surprising since the threshold was optimized on the cost function of predicted loan return. Each of these metrics had an optimal threshold region that was different from the threshold that maximized the difference in the prediction error expressed as a cost function - the average error in the model's predicted returns.\n",
    "2. By definition, `TPR` and `F2` are close to eachother since they minimize `FN`. This was also seen earlier in the metric-based threshold tuning plots and is again observed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_roc_curves(\n",
    "    y_test,\n",
    "    y_probs_test,\n",
    "    type(best_pipe.named_steps[\"clf\"]).__name__,\n",
    "    axis_tick_label_fontsize=12,\n",
    "    wspace=0.1,\n",
    "    legend_position=(0.3, 1.1),\n",
    "    f2_beta=2,\n",
    "    fig_size=(12, 4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Interpreting the ROC-AUC curve\n",
    "   - On average, a model with skill gives a higher probability to a randomly chosen real positive outcome than a negative one.\n",
    "   - A model with perfect skill is depicted as a point at `(0, 1)` (top left of the plot)\n",
    "     - A model with skill produces a ROC-AUC curve that expands from the 45-degree line up to the top left of the plot.\n",
    "2. Interpreting the Precision-Recall curve\n",
    "   - A model with skill can discriminate between classes and does not predict a random class or a constant class in all cases.\n",
    "   - The no-skill line is a horizontal line with the value of the ratio of positive cases in the dataset. Its value depends on the relative balance between positive to negative classes. For a prefectly balanced dataset, this ratio is 0.5, which is clearly not the case here.\n",
    "     - for the test set here, `y_test.value_counts().to_dict()` gives `{0: 10698, 1: 1771}` and so the no-skill line is drawn at `1771/10698`\n",
    "   - A model with perfect skill is depicted as a point at `(1, 1)` (top right of the plot)\n",
    "   - A model with skill produces a Precision-Recall curve that expands from the horizontal line, at the bottom, to the top right of the plot and is well above the horizontal line of no skill.\n",
    "3. Given the imbalance in the classes here, more importance should be given to the Precision-Recall curve than to the ROC-AUC curve.\n",
    "4. While both plots are clearly sub-optimal, it is reassuring that the best model found here is better than one that has no skill.\n",
    "5. The optimal threshold is marked as a circle with an annotation on the\n",
    "   - ROC-AUC curve\n",
    "     - This is the threshold with the optimal balance between false positive and true positive rates as determined by optimizing the Geometric Mean\n",
    "   - Precision-Recall curve\n",
    "     - This is the threshold with the the best balance of precision and recall as determined by as optimizing the [F2 score](https://clusteval.sdu.dk/1/clustering_quality_measures/14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-Neutral Permutation Importance\n",
    "\n",
    "In permutation importance ([1](https://academic.oup.com/bioinformatics/article/26/10/1340/193348), [2](https://docs.cloud.oracle.com/en-us/iaas/tools/ads-sdk/latest/user_guide/mlx/permutation_importance.html#description)), each column is iteratively randomized and used as an input for modeling. The difference in scoring metric with and without this randomization is taken as the importance of the column being randomized to the model. This process is repeated for each column individually. It provides a model agnostic indication of the importance of each feature, independent of how the algorithm's coefficients/importances are computed. The method requires the absence of multi-collinearity between ML features and that is the case here since correlated features were manually removed during exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Methodology Used**\n",
    "1. For a given (`r`, `n`, `P`), calculate\n",
    "   - predicted return per loan ( `A` )\n",
    "     - calculate predicted return from confusion matrix, using formula for `ds`\n",
    "       - this takes ML model's predictive power into account\n",
    "   - true return per loan (`B`)\n",
    "2. Calculate difference (`D`) between predicted and theoretical returns\n",
    "   - `D` = `A` - `B`\n",
    "3. Calculate mean of all differences in the testing data\n",
    "   - this gives the average difference between the return predicted by the model and the return earned (depending on whether the loan was paid off on time or not), per loan ( $\\overline{D}$ )\n",
    "4. Shuffle single ML feature and re-calculate mean of differences ( $\\overline{D}$ ) from step 2.\n",
    "4. Calculate difference (`D1`) bewteen mean values found in steps 2. (without shuffling) and 3. (with shuffling)\n",
    "5. Repeat steps 2. to 4. `n_repeats` times\n",
    "   - in other words, shuffle the same column `n_repeats` times and calculate the differences (`D2`, ..., `D10`) between the predicted and true returns\n",
    "6. Plot all the differences `D1`, ..., `D10`\n",
    "7. The higher the difference the more impactful the ML feature is to the predictive model developed here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a boxplot highlighting the impact on model performance, separately using the TPR (minimizes `FN`), FPR and F2 score (the prefered metric for imbalanced data where `FN` is more important than `FP`) as the scoring metric, of randomizing columns from the testing data individually (i.e. as determined using the permutation importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_permutation_importances(\n",
    "    best_pipe,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    scorer=multi_scorers[\"recall_binary\"],\n",
    "    n_repeats=10,\n",
    "    fig_title_fontsize=14,\n",
    "    fig_title_vertical_pos=0.97,\n",
    "    axis_tick_label_fontsize=12,\n",
    "    axis_label_fontsize=14,\n",
    "    box_color=\"cyan\",\n",
    "    fig_size=(8, 8),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# plot_permutation_importances(\n",
    "#     best_pipe,\n",
    "#     X_test,\n",
    "#     y_test,\n",
    "#     scorer=multi_scorers[\"fpr\"],\n",
    "#     n_repeats=10,\n",
    "#     fig_title_fontsize=14,\n",
    "#     fig_title_vertical_pos=0.97,\n",
    "#     axis_tick_label_fontsize=12,\n",
    "#     axis_label_fontsize=14,\n",
    "#     box_color=\"cyan\",\n",
    "#     fig_size=(8, 8),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_permutation_importances(\n",
    "    best_pipe,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    scorer=multi_scorers[\"f2\"],\n",
    "    n_repeats=10,\n",
    "    fig_title_fontsize=14,\n",
    "    fig_title_vertical_pos=0.97,\n",
    "    axis_tick_label_fontsize=12,\n",
    "    axis_label_fontsize=14,\n",
    "    box_color=\"cyan\",\n",
    "    fig_size=(8, 8),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process is repeated using the difference between the average difference of the model's predicted, and true return, per loan in the testing split as the scoring metric instead of the the TPR and FPR separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "manual_plot_permutation_importance(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    best_pipe,\n",
    "    best_t,\n",
    "    5,\n",
    "    \"test\",\n",
    "    \"Permutation Importances\",\n",
    "    14,\n",
    "    12,\n",
    "    14,\n",
    "    \"cyan\",\n",
    "    (8,8),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. The `int_rate` (loan's interest rate), `term` (duration of loan) and `loan_amnt` (principal) are required to calculate the interrest income which is used in converting the model's predictions to the per-loan return. By definition, shuffling each of these columns individually will affect this conversion. So, it is not surprising that these three are the most important factors as determined by permutation importance.\n",
    "2. Not surprisingly, annual income followed by purpose were the two most influential value-add variables in the data. The annual income is more important than the length of employment - a higher earner is more impactful on the ability to pay off a loan than an applicant who has been working longer (but not earning a high salary).\n",
    "3. Since this is the **average** difference in dollars (horizontal axis) per loan, the marginal value increases in the per-loan return between pairs of features (eg. `annual_inc` vs `purpose`) should also be interpreted as an average rather than a discrete value that can be expected for every single loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_scorers = {\n",
    "    \"recall_binary\": mr.make_scorer(\n",
    "        threshold_recall_score,\n",
    "        greater_is_better=True,\n",
    "        needs_proba=True,\n",
    "        threshold=best_t,\n",
    "    ),\n",
    "    \"f2\": mr.make_scorer(\n",
    "        threshold_fpr_score,\n",
    "        greater_is_better=False,\n",
    "        needs_proba=True,\n",
    "        threshold=best_t,\n",
    "    ),\n",
    "    \"fpr\": mr.make_scorer(\n",
    "        threshold_f2_score,\n",
    "        greater_is_better=False,\n",
    "        needs_proba=True,\n",
    "        threshold=best_t,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check of Bias and Variance using Learning Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and cross-validation learning curves are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "X_all = pd.concat([X_train_val.iloc[:, :], X_test.iloc[:, :]]).reset_index(drop=True)\n",
    "y_all = pd.concat([y_train_val[:], y_test[:]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, these are shown using the `TPR` (or `Recall`) as the scoring metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# plot_learning_curve(\n",
    "#     best_pipe,\n",
    "#     f\"Learning Curves for {type(best_pipe.named_steps['clf']).__name__}\",\n",
    "#     X=X_all,\n",
    "#     y=y_all,\n",
    "#     cv=cv,\n",
    "#     scorer=multi_scorers[\"recall_binary\"],\n",
    "#     n_jobs=-1,\n",
    "#     train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "#     legend_coords=(0.7, 1),\n",
    "#     axis_tick_label_fontsize=12,\n",
    "#     fig_size=(8, 12),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are now shown using the `FPR` as the scoring metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# plot_learning_curve(\n",
    "#     best_pipe,\n",
    "#     f\"Learning Curves for {type(best_pipe.named_steps['clf']).__name__}\",\n",
    "#     X=X_all,\n",
    "#     y=y_all,\n",
    "#     cv=cv,\n",
    "#     scorer=multi_scorers[\"fpr\"],\n",
    "#     n_jobs=-1,\n",
    "#     train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "#     legend_coords=(0.7, 1),\n",
    "#     axis_tick_label_fontsize=12,\n",
    "#     fig_size=(8, 12),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, these are now shown using the `F2` score as the scoring metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_learning_curve(\n",
    "    best_pipe,\n",
    "    f\"Learning Curves for {type(best_pipe.named_steps['clf']).__name__}\",\n",
    "    X=X_all,\n",
    "    y=y_all,\n",
    "    cv=cv,\n",
    "    scorer=multi_scorers[\"f2\"],\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "    legend_coords=(0.7, 1),\n",
    "    axis_tick_label_fontsize=12,\n",
    "    fig_size=(8, 12),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the ML feature permutation importances, poor performance is expected for these metrics since the discrumination threshold was not chosen to optimize any of them. Instead, the focus was on the cost function - here, this is the model's predicted return per loan. So, these learning curves are repeated using the per-loan difference between the predicted and true returns (i.e. the mean error of the model's predictions) as the scoring metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# scores, train_sizes = learning_curve(best_pipe, X_all, y_all, cv, 5, best_t)\n",
    "# scores_grouped = scores.groupby([\"train_size\"]).agg({\"train_err\": [\"mean\", \"std\"], \"test_err\": [\"mean\", \"std\"], \"fit_time\": [\"mean\", \"std\"], \"clf\":\"first\"}).reset_index()\n",
    "# scores_grouped.columns = scores_grouped.columns.map('|'.join)\n",
    "# display(scores_grouped)\n",
    "# manual_learning_curve(\n",
    "#     scores_grouped,\n",
    "#     alpha=0.2,\n",
    "#     hspace=0.2,\n",
    "#     wspace=0.2,\n",
    "#     axis_tick_label_fontsize=12,\n",
    "#     figsize=(7, 12),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Both training and cross-validation errors are larger (more negative) than $\\$$1,000. If the business objective was to predict the average return<sup>[1](#myfootnote1)</sup>\n",
    " per loan to within $\\$$1,000 of the true return<sup>[1](#myfootnote1)</sup> earned per loan, then the error in the model's predictions (both on training and cross-validation splits of the data) would be considered high. This is an indication that the model's predictions suffer from high bias.\n",
    "2. The gap between the two learning curves is small, indicating the presence of low variance in the model's predictions.\n",
    "3. Combined, this indicates that the best model with the selected discrimination threshold is underfitting the training data. Adding data is unlikely to remedy this problem. This is seen from the convergence of the two learning curves as the size of the training data is increased.\n",
    "4. Further work should focus on extracting more features from the dataset - currently only a single ML feature `is_employed` (a binary column indicating whether the applicant was employed or not at the time of applying for the loan on Lending Club) was extracted.\n",
    "\n",
    "<a name=\"myfootnote1\">1</a>: or loss, depending on whether the loan is paid off on time or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_test_selected_threshold_series = pd.Series(\n",
    "#     y_pred_test_selected_threshold, index=X_test.index, name=\"pred\"\n",
    "# )\n",
    "# df_tp = df[[\"addr_state\"]].merge(\n",
    "#     pd.concat(\n",
    "#         [\n",
    "#             X_test[\n",
    "#                 [\n",
    "#                     \"purpose\",\n",
    "#                     \"home_ownership\",\n",
    "#                     \"emp_length\",\n",
    "#                     \"term\",\n",
    "#                 ]\n",
    "#                 + numerical_columns\n",
    "#             ],\n",
    "#             y_test,\n",
    "#             y_pred_test_selected_threshold_series,\n",
    "#         ],\n",
    "#         axis=1,\n",
    "#     ),\n",
    "#     left_index=True,\n",
    "#     right_index=True,\n",
    "#     how=\"inner\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tp[\"misclassified\"] = df_tp[\"is_default\"] != df_tp[\"pred\"]\n",
    "# display(df_tp)\n",
    "# display(df_tp.dtypes.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in numerical_columns:\n",
    "#     plot_grouped_histogram(df_tp, c, (0.675, 1.1), 0.5, 0.15, (12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col, wspace, fig_size in zip(\n",
    "#     [\"home_ownership\", \"purpose\", \"emp_length\", \"term\", \"addr_state\"],\n",
    "#     [0.25, 0.4, 0.1, 0.25, 0.1],\n",
    "#     [(12, 4), (12, 4), (12, 4), (12, 4), (12, 8)],\n",
    "# ):\n",
    "#     plot_grouped_bar_chart(df_tp, col, \"misclassified\", wspace, fig_size=fig_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "1. [Find row closest to a value](https://stackoverflow.com/a/52587453/4057186)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
