{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    FunctionTransformer,\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.custom_transformers\n",
    "from src.custom_transformers import (\n",
    "    DFNanThresholdColumnDropper,\n",
    "    DFColumnDropper,\n",
    "    DFColumnFilterList,\n",
    "    DFColumnMapper,\n",
    "    DFNonUniqueValColDropper,\n",
    "    DFDropNaN,\n",
    "    DFOneHotEncoder,\n",
    "    DFPctNumeric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 2000)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs and helper functions are defined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "raw_data_path = \"data/raw/lending_club_loans.csv\"\n",
    "cloud_storage = \"no\"\n",
    "\n",
    "# From Feature Reduction\n",
    "nan_threshold = 0.5\n",
    "non_useful_cols = [\"url\", \"desc\"]\n",
    "datetime_cols1 = [\"issue_d\", \"last_pymnt_d\"]\n",
    "cols_one_eighteen = [\n",
    "    \"id\",\n",
    "    \"member_id\",\n",
    "    \"funded_amnt\",\n",
    "    \"funded_amnt_inv\",\n",
    "    \"grade\",\n",
    "    \"sub_grade\",\n",
    "    \"emp_title\",\n",
    "]\n",
    "cols_eighteen_thirtysix = [\n",
    "    \"zip_code\",\n",
    "    \"out_prncp\",\n",
    "    \"out_prncp_inv\",\n",
    "    \"total_pymnt\",\n",
    "    \"total_pymnt_inv\",\n",
    "    \"total_rec_prncp\",\n",
    "]\n",
    "cols_thirtyseven_end = [\n",
    "    \"total_rec_int\",\n",
    "    \"total_rec_late_fee\",\n",
    "    \"recoveries\",\n",
    "    \"collection_recovery_fee\",\n",
    "    \"last_pymnt_amnt\",\n",
    "]\n",
    "loan_status = [\"Fully Paid\", \"Charged Off\"]\n",
    "mapping_dictionary = {\"loan_status\": {\"Fully Paid\": 1, \"Charged Off\": 0}}\n",
    "four_or_less_value_columns = [\"pymnt_plan\"]\n",
    "\n",
    "# From Feature Processing\n",
    "more_than_one_pct_missing_columns = [\"pub_rec_bankruptcies\"]\n",
    "datetime_cols2 = [\"last_credit_pull_d\", \"earliest_cr_line\"]\n",
    "high_cardinality_cols = [\"addr_state\"]\n",
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0,\n",
    "    }\n",
    "}\n",
    "nominal_columns = [\"home_ownership\", \"verification_status\", \"purpose\", \"term\"]\n",
    "repeated_data_cols = [\"title\"]\n",
    "pct_to_numeric_cols = [\"int_rate\", \"revol_util\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_threshold = float(nan_threshold)\n",
    "for k in [\"Fully Paid\", \"Charged Off\"]:\n",
    "    mapping_dictionary[\"loan_status\"][k] = int(mapping_dictionary[\"loan_status\"][k])\n",
    "for k in [\n",
    "    \"10+ years\",\n",
    "    \"9 years\",\n",
    "    \"8 years\",\n",
    "    \"7 years\",\n",
    "    \"6 years\",\n",
    "    \"5 years\",\n",
    "    \"4 years\",\n",
    "    \"3 years\",\n",
    "    \"2 years\",\n",
    "    \"1 year\",\n",
    "    \"< 1 year\",\n",
    "    \"n/a\",\n",
    "]:\n",
    "    mapping_dict[\"emp_length\"][k] = int(mapping_dict[\"emp_length\"][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_splines(ax: plt.axis) -> plt.axis:\n",
    "    ax.spines[\"left\"].set_edgecolor(\"black\")\n",
    "    ax.spines[\"left\"].set_linewidth(2)\n",
    "    ax.spines[\"bottom\"].set_edgecolor(\"black\")\n",
    "    ax.spines[\"bottom\"].set_linewidth(2)\n",
    "    ax.spines[\"top\"].set_edgecolor(\"lightgrey\")\n",
    "    ax.spines[\"top\"].set_linewidth(1)\n",
    "    ax.spines[\"right\"].set_edgecolor(\"lightgrey\")\n",
    "    ax.spines[\"right\"].set_linewidth(1)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_by_partial_name(df, partial_col_name):\n",
    "    return df.columns[df.columns.str.contains(partial_col_name)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_get_dummies(df, partial_name):\n",
    "    \"\"\"\n",
    "    > reverse_get_dummies(df, \"purpose_\")\n",
    "    \"\"\"\n",
    "    cols_to_reverse = get_cols_by_partial_name(df, partial_name)\n",
    "    return df[cols_to_reverse].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lower_corr_heatmap(\n",
    "    df_corr, ptitle, lw=1, annot_fmt=\".2f\", ptitle_y_loc=1, fig_size=(10, 10)\n",
    "):\n",
    "    f, ax = plt.subplots(figsize=fig_size)\n",
    "    mask = np.triu(np.ones_like(df_corr, dtype=bool))\n",
    "    sns.heatmap(\n",
    "        df_corr,\n",
    "        mask=mask,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        center=0,\n",
    "        cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "        square=True,\n",
    "        ax=ax,\n",
    "        annot=True,\n",
    "        cbar=False,\n",
    "        linewidths=lw,\n",
    "        fmt=annot_fmt,\n",
    "    )\n",
    "    ax.set_title(ptitle, loc=\"left\", fontweight=\"bold\", y=ptitle_y_loc)\n",
    "    ax.tick_params(left=False, bottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_is_default(df, by, default_col=\"is_default\", is_default=1, ascending=True):\n",
    "    grp = df.groupby([default_col, by])[by].count()\n",
    "    cnt = df.groupby(by)[by].count()\n",
    "    percentages = grp.unstack() * 100 / cnt.T\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    # display(percentages)\n",
    "    if ascending:\n",
    "        percentages = percentages.T.sort_values(by=is_default, ascending=True).T\n",
    "    ax = percentages.loc[is_default].plot.barh(ax=ax, zorder=3)\n",
    "    ax.set_title(\"Percent of loans in default\", loc=\"left\", fontweight=\"bold\")\n",
    "    ax.grid(which=\"both\", axis=\"both\", color=\"lightgrey\", zorder=0)\n",
    "    _ = customize_splines(ax)\n",
    "    ax.set_ylabel(None)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(df, col, default_col=\"is_default\"):\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    grid = plt.GridSpec(1, 2, hspace=0.2, wspace=0.2)\n",
    "    ax1 = fig.add_subplot(grid[0, 0])\n",
    "    ax2 = fig.add_subplot(grid[0, 1])\n",
    "    df[col].plot.hist(ax=ax1, edgecolor=\"white\", zorder=3)\n",
    "    sns.boxplot(data=df, x=col, y=default_col, orient=\"h\", ax=ax2)\n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.grid(which=\"both\", axis=\"both\", color=\"lightgrey\", zorder=0)\n",
    "        _ = customize_splines(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pct_of_data(df, col, wspace=0.9, fig_size=(8, 4)):\n",
    "    df_term = pd.concat(\n",
    "        [reverse_get_dummies(df, f\"{col}_\").rename(col), df[\"is_default\"]], axis=1\n",
    "    )\n",
    "    s1 = 100 * df_term[col].value_counts(normalize=True).sort_values(ascending=True)\n",
    "    s2 = 100 * df_term.loc[df_term[\"is_default\"] == 1][col].value_counts(\n",
    "        normalize=True\n",
    "    ).sort_values(ascending=True)\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    grid = plt.GridSpec(1, 2, wspace=wspace)\n",
    "    ax1 = fig.add_subplot(grid[0, 0])\n",
    "    ax2 = fig.add_subplot(grid[0, 1])\n",
    "    s1.plot(ax=ax1, kind=\"barh\", zorder=3)\n",
    "    s2.plot(ax=ax2, kind=\"barh\", zorder=3)\n",
    "    ax1.set_xlabel(None)\n",
    "    ax2.set_xlabel(None)\n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.grid(which=\"both\", axis=\"both\", color=\"lightgrey\", zorder=0)\n",
    "        _ = customize_splines(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_barplots(df, cols, col_to_agg=\"loan_amnt\"):\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    rows = int(len(cols) / 2)\n",
    "    grid = plt.GridSpec(rows, 2, hspace=0.2, wspace=0.2)\n",
    "    for r in range(rows):\n",
    "        for k in range(2):\n",
    "            # print(r, k, (2 * r) + k)\n",
    "            ax = fig.add_subplot(grid[r, k])\n",
    "            df.groupby(cols[(2 * r) + k])[col_to_agg].count().plot.bar(ax=ax, zorder=3)\n",
    "            ax.grid(which=\"both\", axis=\"both\", color=\"lightgrey\", zorder=0)\n",
    "            ax.set_xticklabels(ax.get_xticklabels(), rotation=22, ha=\"right\")\n",
    "            _ = customize_splines(ax)\n",
    "            ax.set_xlabel(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloud_storage == \"yes\":\n",
    "    az_storage_container_name = \"myconedesx7\"\n",
    "    conn_str = (\n",
    "        \"DefaultEndpointsProtocol=https;\"\n",
    "        f\"AccountName={os.getenv('AZURE_STORAGE_ACCOUNT')};\"\n",
    "        f\"AccountKey={os.getenv('AZURE_STORAGE_KEY')};\"\n",
    "        f\"EndpointSuffix={os.getenv('ENDPOINT_SUFFIX')}\"\n",
    "    )\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(conn_str=conn_str)\n",
    "\n",
    "    blobstrings = {}\n",
    "    for blob_name in [\"blobedesz38\"]:\n",
    "        blob_client = blob_service_client.get_blob_client(\n",
    "            container=az_storage_container_name, blob=blob_name\n",
    "        )\n",
    "        blobstring = blob_client.download_blob().content_as_text()\n",
    "    loans_2007 = pd.read_csv(StringIO(blobstring), skiprows=1, low_memory=False)\n",
    "else:\n",
    "    loans_2007 = pd.read_csv(raw_data_path, skiprows=1, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007, _ = train_test_split(loans_2007, test_size=0.33, random_state=4321)\n",
    "loans_2007 = loans_2007.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_part_1_and_2 = Pipeline(\n",
    "    [\n",
    "        (\"nan1\", DFNanThresholdColumnDropper(nan_threshold)),\n",
    "        (\"nouse\", DFColumnDropper(non_useful_cols)),\n",
    "        (\"dtime1\", DFColumnDropper(datetime_cols1)),\n",
    "        (\"c1\", DFColumnDropper(cols_one_eighteen)),\n",
    "        (\"c2\", DFColumnDropper(cols_eighteen_thirtysix)),\n",
    "        (\"c3\", DFColumnDropper(cols_thirtyseven_end)),\n",
    "        (\n",
    "            \"mapstatus\",\n",
    "            DFColumnFilterList(\"loan_status\", loan_status),\n",
    "        ),\n",
    "        (\"colmap\", DFColumnMapper(mapping_dictionary)),\n",
    "        (\"onevals\", DFNonUniqueValColDropper(1)),\n",
    "        (\"fourvals\", DFColumnDropper(four_or_less_value_columns)),\n",
    "        (\"morethan1pctnan\", DFColumnDropper(more_than_one_pct_missing_columns)),\n",
    "        (\"nan2\", DFDropNaN()),\n",
    "        (\"hcardcols\", DFColumnDropper(high_cardinality_cols)),\n",
    "        (\"dtime2\", DFColumnDropper(datetime_cols2)),\n",
    "        (\"texttonum\", DFColumnMapper(mapping_dict)),\n",
    "        (\"onehot\", DFOneHotEncoder(nominal_columns)),\n",
    "        (\"repeats\", DFColumnDropper(repeated_data_cols)),\n",
    "        (\"pctcols\", DFPctNumeric(pct_to_numeric_cols, \"%\")),\n",
    "    ]\n",
    ")\n",
    "df = pipe_part_1_and_2.fit_transform(loans_2007)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full list of columns in this processed data is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying default loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"loan_status\"].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFSingleColumnMapper(TransformerMixin):\n",
    "    def __init__(self, col, mapping_dict):\n",
    "        self.col = col\n",
    "        self.mapping_dict = mapping_dict\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        X[list(self.mapping_dict.keys())[0]] = X[self.col]\n",
    "        return X.replace(self.mapping_dict)\n",
    "\n",
    "    def fit_transform(self, X, y=None, **kwargs):\n",
    "        self = self.fit(X, y)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFSimpleDtypeChanger(TransformerMixin):\n",
    "    def __init__(self, col, datatype):\n",
    "        self.col = col\n",
    "        self.datatype = datatype\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        X[self.col] = X[self.col].astype(self.datatype)\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None, **kwargs):\n",
    "        self = self.fit(X, y)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_default\"] = [0 if s in [1] else 1 for s in df[\"loan_status\"]]\n",
    "df[\"is_default\"] = df[\"is_default\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\"is_default\": {0: 1, 1: 0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline(\n",
    "#     [\n",
    "#         (\"singlecolmap\", DFSingleColumnMapper(\"loan_status\", mapping_dict)),\n",
    "#         (\"dtype\", DFSimpleDtypeChanger(\"is_default\", \"int\")),\n",
    "#     ]\n",
    "# )\n",
    "# df = pipe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_default.value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown of default vs non-default loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.hist(\n",
    "    df[df.is_default == 0][\"loan_amnt\"],\n",
    "    bins=7,\n",
    "    edgecolor=\"white\",\n",
    "    stacked=True,\n",
    "    label=\"non-default\",\n",
    "    zorder=3,\n",
    ")\n",
    "ax.hist(\n",
    "    df[df.is_default == 1][\"loan_amnt\"],\n",
    "    bins=7,\n",
    "    edgecolor=\"white\",\n",
    "    stacked=True,\n",
    "    label=\"default\",\n",
    "    zorder=3,\n",
    ")\n",
    "ax.set_title(\"Loan Amount ($)\", loc=\"left\", fontweight=\"bold\")\n",
    "ax.legend(frameon=False)\n",
    "ax.grid(which=\"both\", axis=\"both\", color=\"lightgrey\", zorder=0)\n",
    "_ = customize_splines(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose_cols = get_cols_by_partial_name(df, \"purpose_\")\n",
    "loans = []\n",
    "for purpose_col in purpose_cols:\n",
    "    good = (\n",
    "        100\n",
    "        * np.sum([(df[purpose_col] == 1) & (df.is_default == 0)])\n",
    "        / np.sum(df[purpose_col] == 1)\n",
    "    )\n",
    "    bad = (\n",
    "        100\n",
    "        * np.sum([(df[purpose_col] == 1) & (df.is_default == 1)])\n",
    "        / np.sum(df[purpose_col] == 1)\n",
    "    )\n",
    "    loans.append([purpose_col, good, bad])\n",
    "\n",
    "loans = pd.DataFrame(loans)\n",
    "loans.columns = [\"Purpose\", \"Non-default\", \"Default\"]\n",
    "loans.set_index(\"Purpose\", inplace=True)\n",
    "loans.sort_values(\"Non-default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=loans.stack().reset_index(),\n",
    "    kind=\"bar\",\n",
    "    orient=\"h\",\n",
    "    hue=\"level_1\",\n",
    "    y=\"Purpose\",\n",
    "    x=0,\n",
    "    ci=\"sd\",\n",
    "    palette=\"dark\",\n",
    "    height=5,\n",
    "    aspect=1.5,\n",
    "    zorder=3,\n",
    ")\n",
    "g.set_axis_labels(\"\", \"\")\n",
    "g.legend.set_title(\"\")\n",
    "plt.grid(zorder=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"loan_amnt\", \"is_default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_amnt_bin = pd.cut(\n",
    "    df[\"loan_amnt\"],\n",
    "    [x for x in range(0, 36000, 5000)],\n",
    "    labels=[str(x) + \"-\" + str(x + 5) + \"k\" for x in range(0, 35, 5)],\n",
    ").rename(\"loan_amnt_bin\")\n",
    "plot_is_default(\n",
    "    pd.concat([df[\"is_default\"], loan_amnt_bin], axis=1), \"loan_amnt_bin\", \"is_default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"loan_amnt\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {\n",
    "    \"bc\": PowerTransformer(\"box-cox\"),\n",
    "    \"yj\": PowerTransformer(\"yeo-johnson\"),\n",
    "    \"qn\": QuantileTransformer(output_distribution=\"normal\", n_quantiles=len(df) - 1),\n",
    "    \"qu\": QuantileTransformer(output_distribution=\"uniform\", n_quantiles=len(df) - 1),\n",
    "    \"l\": FunctionTransformer(np.log1p, inverse_func=np.expm1),\n",
    "}\n",
    "pipe_trans = Pipeline([(\"trans\", transformers[\"bc\"])])\n",
    "plot_distribution(\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(pipe_trans.fit_transform(df[[\"loan_amnt\"]])).rename(\n",
    "                columns={0: \"loan_amnt\"}\n",
    "            ),\n",
    "            df[\"is_default\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    \"loan_amnt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- all transformers be used\n",
    "- **all transformers should be compared**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_cols = [\"home_ownership\", \"term\", \"verification_status\", \"purpose\"]\n",
    "df_cats = pd.concat(\n",
    "    [reverse_get_dummies(df, f\"{c}_\").rename(c) for c in cats_cols],\n",
    "    axis=1,\n",
    ")\n",
    "plot_multiple_barplots(\n",
    "    pd.concat([df_cats, df[\"loan_amnt\"]], axis=1), cats_cols, col_to_agg=\"loan_amnt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pct_of_data(df, \"term\", 0.9, (6, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pct_of_data(df, \"purpose\", 0.7, (12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "df[get_cols_by_partial_name(df, \"purpose_\")].sum().sort_values(ascending=True).plot(\n",
    "    ax=ax, kind=\"barh\", zorder=3\n",
    ")\n",
    "ax.grid(which=\"both\", axis=\"both\", color=\"lightgrey\", zorder=0)\n",
    "_ = customize_splines(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = df.set_index(\"is_default\")[get_cols_by_partial_name(df, \"purpose_\")]\n",
    "plot_is_default(\n",
    "    df_proc[df_proc == 1].stack().reset_index().drop(0, 1), \"level_1\", \"is_default\", 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = []\n",
    "for purpose_col in purpose_cols:\n",
    "    good = (\n",
    "        100\n",
    "        * np.sum([(df[purpose_col] == 1) & (df.is_default == 0)])\n",
    "        / len(df[purpose_col] == 1)\n",
    "    )\n",
    "    bad = (\n",
    "        100\n",
    "        * np.sum([(df[purpose_col] == 1) & (df.is_default == 1)])\n",
    "        / len(df[purpose_col] == 1)\n",
    "    )\n",
    "    loans.append([purpose_col, good, bad])\n",
    "\n",
    "loans = pd.DataFrame(loans)\n",
    "loans.columns = [\"Purpose\", \"Non-default\", \"Default\"]\n",
    "loans.set_index(\"Purpose\", inplace=True)\n",
    "loans.sort_values(\"Non-default\")\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=loans.stack().sort_values(ascending=False).reset_index(),\n",
    "    kind=\"bar\",\n",
    "    orient=\"h\",\n",
    "    hue=\"level_1\",\n",
    "    y=\"Purpose\",\n",
    "    x=0,\n",
    "    ci=\"sd\",\n",
    "    palette=\"dark\",\n",
    "    height=6,\n",
    "    aspect=1,\n",
    "    zorder=3,\n",
    ")\n",
    "g.set_axis_labels(\"\", \"\")\n",
    "g.legend.set_title(\"\")\n",
    "plt.grid(zorder=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"int_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_is_default(\n",
    "    pd.concat([df[\"is_default\"], round(df[\"int_rate\"])], axis=1),\n",
    "    \"int_rate\",\n",
    "    \"is_default\",\n",
    "    1,\n",
    "    False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"int_rate\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {\n",
    "    \"bc\": PowerTransformer(\"box-cox\"),\n",
    "    \"yj\": PowerTransformer(\"yeo-johnson\"),\n",
    "    \"qn\": QuantileTransformer(output_distribution=\"normal\", n_quantiles=len(df) - 1),\n",
    "    \"qu\": QuantileTransformer(output_distribution=\"uniform\", n_quantiles=len(df) - 1),\n",
    "    \"l\": FunctionTransformer(np.log1p, inverse_func=np.expm1),\n",
    "}\n",
    "pipe_trans = Pipeline([(\"trans\", transformers[\"l\"])])\n",
    "plot_distribution(\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(pipe_trans.fit_transform(df[[\"int_rate\"]])).rename(\n",
    "                columns={0: \"int_rate\"}\n",
    "            ),\n",
    "            df[\"is_default\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    \"int_rate\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- all transformers be used\n",
    "- **all transformers (incl. `log`) should be compared**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"installment\", \"is_default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"installment\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"emp_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emp_length = pd.get_dummies(df[\"emp_length\"], prefix=\"emp_length\").assign(\n",
    "    is_default=df[\"is_default\"]\n",
    ")\n",
    "plot_pct_of_data(df_emp_length, \"emp_length\", 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"emp_length\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {\n",
    "    \"bc\": PowerTransformer(\"box-cox\"),\n",
    "    \"yj\": PowerTransformer(\"yeo-johnson\"),\n",
    "    \"qn\": QuantileTransformer(output_distribution=\"normal\", n_quantiles=len(df) - 1),\n",
    "    \"qu\": QuantileTransformer(output_distribution=\"uniform\", n_quantiles=len(df) - 1),\n",
    "    \"l\": FunctionTransformer(np.log1p, inverse_func=np.expm1),\n",
    "}\n",
    "pipe_trans = Pipeline([(\"trans\", transformers[\"qu\"])])\n",
    "plot_distribution(\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(pipe_trans.fit_transform(df[[\"emp_length\"]])).rename(\n",
    "                columns={0: \"emp_length\"}\n",
    "            ),\n",
    "            df[\"is_default\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    \"emp_length\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- Box-Cox cannot be used\n",
    "- none of the transformers seem effective, likely due to the large number of loans for individuals with 10 or more years of employment\n",
    "  - it seems intuitive that these records should be retained and not filtered out\n",
    "- **all transformers should be compared OR leave the column un-transformed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pct_of_data(df, \"home_ownership\", 1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"annual_inc\", \"is_default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annual_inc_3std = df[\n",
    "#     np.abs(df[\"annual_inc\"] - df[\"annual_inc\"].mean()) <= (3 * df[\"annual_inc\"].std())\n",
    "# ]\n",
    "df = df[\n",
    "    np.abs(df[\"annual_inc\"] - df[\"annual_inc\"].mean()) <= (3 * df[\"annual_inc\"].std())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(\n",
    "    df,\n",
    "    \"annual_inc\",\n",
    "    \"is_default\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"annual_inc\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {\n",
    "    \"bc\": PowerTransformer(\"box-cox\"),\n",
    "    \"yj\": PowerTransformer(\"yeo-johnson\"),\n",
    "    \"qn\": QuantileTransformer(output_distribution=\"normal\", n_quantiles=len(df) - 1),\n",
    "    \"qu\": QuantileTransformer(output_distribution=\"uniform\", n_quantiles=len(df) - 1),\n",
    "    \"l\": FunctionTransformer(np.log1p, inverse_func=np.expm1),\n",
    "}\n",
    "pipe_trans = Pipeline([(\"trans\", transformers[\"yj\"])])\n",
    "plot_distribution(\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(pipe_trans.fit_transform(df[[\"annual_inc\"]])).rename(\n",
    "                columns={0: \"annual_inc\"}\n",
    "            ),\n",
    "            df[\"is_default\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    \"annual_inc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- any transformer can be used\n",
    "- **all transformers (incl. `log`) should be compared on filtered version of this column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFColumnStdFilter(TransformerMixin):\n",
    "    def __init__(self, col, n_std):\n",
    "        self.col = col\n",
    "        self.n_std = n_std\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        return X[\n",
    "            np.abs(X[self.col] - X[self.col].mean()) <= (self.n_std * X[self.col].std())\n",
    "        ]\n",
    "\n",
    "    def fit_transform(self, X, y=None, **kwargs):\n",
    "        self = self.fit(X, y)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline(\n",
    "#     [\n",
    "#         (\"stdfilter\", DFColumnStdFilter(\"annual_inc\", 3)),\n",
    "#     ]\n",
    "# )\n",
    "# df = pipe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pct_of_data(df, \"verification_status\", 1.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `dti` - Monthly payments on debt obligations (excl. this loan) divided by monthly income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"dti\", \"is_default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_bin = pd.cut(\n",
    "    df[\"dti\"],\n",
    "    [x for x in range(0, 30 + 5, 5)],\n",
    "    labels=[str(x) + \"-\" + str(x + 5) for x in range(0, 30, 5)],\n",
    ").rename(\"dti_bin\")\n",
    "plot_is_default(\n",
    "    pd.concat([df[\"is_default\"], dti_bin], axis=1), \"dti_bin\", \"is_default\", 1, False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"dti\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {\n",
    "    \"bc\": PowerTransformer(\"box-cox\"),\n",
    "    \"yj\": PowerTransformer(\"yeo-johnson\"),\n",
    "    \"qn\": QuantileTransformer(output_distribution=\"normal\", n_quantiles=len(df) - 1),\n",
    "    \"qu\": QuantileTransformer(output_distribution=\"uniform\", n_quantiles=len(df) - 1),\n",
    "    \"l\": FunctionTransformer(np.log1p, inverse_func=np.expm1),\n",
    "}\n",
    "pipe_trans = Pipeline([(\"trans\", transformers[\"yj\"])])\n",
    "plot_distribution(\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(pipe_trans.fit_transform(df[[\"dti\"]])).rename(\n",
    "                columns={0: \"dti\"}\n",
    "            ),\n",
    "            df[\"is_default\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    \"dti\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- Box-Cox cannot be used\n",
    "- power transformers seem more effective than Yeo-Johnson\n",
    "- **all transformers should be compared (preference to power)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `delinq_2yrs` - Number of greater than one month delinquincies over the last two years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"delinq_2yrs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"delinq_2yrs\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {\n",
    "    \"bc\": PowerTransformer(\"box-cox\"),\n",
    "    \"yj\": PowerTransformer(\"yeo-johnson\"),\n",
    "    \"qn\": QuantileTransformer(output_distribution=\"normal\", n_quantiles=len(df) - 1),\n",
    "    \"qu\": QuantileTransformer(output_distribution=\"uniform\", n_quantiles=len(df) - 1),\n",
    "    \"l\": FunctionTransformer(np.log1p, inverse_func=np.expm1),\n",
    "}\n",
    "pipe_trans = Pipeline([(\"trans\", transformers[\"yj\"])])\n",
    "plot_distribution(\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                pipe_trans.fit_transform(df[df[\"delinq_2yrs\"] < 2][[\"delinq_2yrs\"]])\n",
    "            ).rename(columns={0: \"delinq_2yrs\"}),\n",
    "            df[\"is_default\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    \"delinq_2yrs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- Box-Cox cannot be used\n",
    "- none of the transformers seem effective\n",
    "  - without more exhaustive exploratory analysis, this seems like an important column so it should not be dropped\n",
    "- **all transformers should be compared OR (prefered) leave column un-transformed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_is_default(df, \"delinq_2yrs\", \"is_default\", 1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `inq_last_6_mths` - Number of inquiries over the last six years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(100 * df[\"inq_last_6mths\"].value_counts(normalize=True)).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_is_default(df, \"inq_last_6mths\", \"is_default\", 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"inq_last_6mths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df[df[\"inq_last_6mths\"] <= 3], \"inq_last_6mths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"inq_last_6mths\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {\n",
    "    \"bc\": PowerTransformer(\"box-cox\"),\n",
    "    \"yj\": PowerTransformer(\"yeo-johnson\"),\n",
    "    \"qn\": QuantileTransformer(output_distribution=\"normal\", n_quantiles=len(df) - 1),\n",
    "    \"qu\": QuantileTransformer(output_distribution=\"uniform\", n_quantiles=len(df) - 1),\n",
    "    \"l\": FunctionTransformer(np.log1p, inverse_func=np.expm1),\n",
    "}\n",
    "pipe_trans = Pipeline([(\"trans\", transformers[\"yj\"])])\n",
    "plot_distribution(\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                pipe_trans.fit_transform(\n",
    "                    df[df[\"inq_last_6mths\"] <= 3][[\"inq_last_6mths\"]]\n",
    "                )\n",
    "            ).rename(columns={0: \"inq_last_6mths\"}),\n",
    "            df[\"is_default\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    \"inq_last_6mths\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- Box-Cox cannot be used\n",
    "- none of the transformers seem effective\n",
    "- **all transformers should be compared OR (prefered) leave column un-transformed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open credit lines on file for borrower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"open_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"open_acc\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {\n",
    "    \"bc\": PowerTransformer(\"box-cox\"),\n",
    "    \"yj\": PowerTransformer(\"yeo-johnson\"),\n",
    "    \"qn\": QuantileTransformer(output_distribution=\"normal\", n_quantiles=len(df) - 1),\n",
    "    \"qu\": QuantileTransformer(output_distribution=\"uniform\", n_quantiles=len(df) - 1),\n",
    "    \"l\": FunctionTransformer(np.log1p, inverse_func=np.expm1),\n",
    "}\n",
    "pipe_trans = Pipeline([(\"trans\", transformers[\"qn\"])])\n",
    "plot_distribution(\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(pipe_trans.fit_transform(df[[\"open_acc\"]])).rename(\n",
    "                columns={0: \"open_acc\"}\n",
    "            ),\n",
    "            df[\"is_default\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    \"open_acc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- with strictly positive value, any transformer can be used\n",
    "- even without filtering outliers, all transformers seem effective\n",
    "- **all transformers should be compared**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revolving Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"revol_bal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df[df[\"revol_bal\"] <= 30000], \"revol_bal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"revol_bal\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {\n",
    "    \"bc\": PowerTransformer(\"box-cox\"),\n",
    "    \"yj\": PowerTransformer(\"yeo-johnson\"),\n",
    "    \"qn\": QuantileTransformer(output_distribution=\"normal\", n_quantiles=len(df) - 1),\n",
    "    \"qu\": QuantileTransformer(output_distribution=\"uniform\", n_quantiles=len(df) - 1),\n",
    "    \"l\": FunctionTransformer(np.log1p, inverse_func=np.expm1),\n",
    "}\n",
    "pipe_trans = Pipeline([(\"trans\", transformers[\"yj\"])])\n",
    "plot_distribution(\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(pipe_trans.fit_transform(df[[\"revol_bal\"]])).rename(\n",
    "                columns={0: \"revol_bal\"}\n",
    "            ),\n",
    "            df[\"is_default\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    \"revol_bal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- filtering out values greater than $30,000, from the un-transformed data in this column, eliminates outliters\n",
    "  - more exhaustive analysis is needed to determine if this is acceptable\n",
    "- for transforming the un-filtered data in this column\n",
    "  - since the minimum value is zero, the Box-Cox transformation (requiring strictly positive values) [cannot be used](https://en.wikipedia.org/wiki/Power_transform#Box%E2%80%93Cox_transformation)\n",
    "- **all transformers should be compared**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative used credit (compared to available revolving credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"revol_util\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"revol_util\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {\n",
    "    \"bc\": PowerTransformer(\"box-cox\"),\n",
    "    \"yj\": PowerTransformer(\"yeo-johnson\"),\n",
    "    \"qn\": QuantileTransformer(output_distribution=\"normal\", n_quantiles=len(df) - 1),\n",
    "    \"qu\": QuantileTransformer(output_distribution=\"uniform\", n_quantiles=len(df) - 1),\n",
    "    \"l\": FunctionTransformer(np.log1p, inverse_func=np.expm1),\n",
    "}\n",
    "pipe_trans = Pipeline([(\"trans\", transformers[\"qn\"])])\n",
    "plot_distribution(\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(pipe_trans.fit_transform(df[[\"revol_util\"]])).rename(\n",
    "                columns={0: \"revol_util\"}\n",
    "            ),\n",
    "            df[\"is_default\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    \"revol_util\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- filtering out values greater than $30,000, from the un-transformed data in this column, eliminates outliters\n",
    "  - more exhaustive analysis is needed to determine if this is acceptable\n",
    "- for transforming the un-filtered data in this column\n",
    "  - Box-Cox transformation cannot be used due to zero values\n",
    "  - log and Yeo-Johnson are not as effective, possibly due to the large number of values between 0 and 10\n",
    "    - should preference be given to power transformations?\n",
    "- **all transformers should be compared (preference to quantile)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pub_rec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"pub_rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_is_default(df, \"pub_rec\", \"is_default\", 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"pub_rec\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {\n",
    "    \"bc\": PowerTransformer(\"box-cox\"),\n",
    "    \"yj\": PowerTransformer(\"yeo-johnson\"),\n",
    "    \"qn\": QuantileTransformer(output_distribution=\"normal\", n_quantiles=len(df) - 1),\n",
    "    \"qu\": QuantileTransformer(output_distribution=\"uniform\", n_quantiles=len(df) - 1),\n",
    "    \"l\": FunctionTransformer(np.log1p, inverse_func=np.expm1),\n",
    "}\n",
    "pipe_trans = Pipeline([(\"trans\", transformers[\"l\"])])\n",
    "plot_distribution(\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(pipe_trans.fit_transform(df[[\"pub_rec\"]])).rename(\n",
    "                columns={0: \"pub_rec\"}\n",
    "            ),\n",
    "            df[\"is_default\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    \"pub_rec\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- **leave un-transformed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of credit lines on file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"total_acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FICO range (low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"fico_range_low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"fico_range_low\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {\n",
    "    \"bc\": PowerTransformer(\"box-cox\"),\n",
    "    \"yj\": PowerTransformer(\"yeo-johnson\"),\n",
    "    \"qn\": QuantileTransformer(output_distribution=\"normal\", n_quantiles=len(df) - 1),\n",
    "    \"qu\": QuantileTransformer(output_distribution=\"uniform\", n_quantiles=len(df) - 1),\n",
    "    \"l\": FunctionTransformer(np.log1p, inverse_func=np.expm1),\n",
    "}\n",
    "pipe_trans = Pipeline([(\"trans\", transformers[\"bc\"])])\n",
    "plot_distribution(\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(pipe_trans.fit_transform(df[[\"fico_range_low\"]])).rename(\n",
    "                columns={0: \"fico_range_low\"}\n",
    "            ),\n",
    "            df[\"is_default\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    \"fico_range_low\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- **all transformers (except Yeo-Johnson, which produced division by zero), incl. `log`, should be compared**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FICO range (high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df, \"fico_range_high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"is_default\")[\"fico_range_high\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {\n",
    "    \"bc\": PowerTransformer(\"box-cox\"),\n",
    "    \"yj\": PowerTransformer(\"yeo-johnson\"),\n",
    "    \"qn\": QuantileTransformer(output_distribution=\"normal\", n_quantiles=len(df) - 1),\n",
    "    \"qu\": QuantileTransformer(output_distribution=\"uniform\", n_quantiles=len(df) - 1),\n",
    "    \"l\": FunctionTransformer(np.log1p, inverse_func=np.expm1),\n",
    "}\n",
    "pipe_trans = Pipeline([(\"trans\", transformers[\"bc\"])])\n",
    "plot_distribution(\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(pipe_trans.fit_transform(df[[\"fico_range_high\"]])).rename(\n",
    "                columns={0: \"fico_range_high\"}\n",
    "            ),\n",
    "            df[\"is_default\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    \"fico_range_high\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- **(same as for `fico_range_low`) all transformers (except Yeo-Johnson, which produced division by zero), incl. `log`, should be compared**\n",
    "  - this feature is likely correlated to `fico_range_low`, so only one of the two should be kept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan amount compared to Annual income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.jointplot(\n",
    "        x=\"annual_inc\",\n",
    "        y=\"loan_amnt\",\n",
    "        hue=\"is_default\",\n",
    "        data=df.loc[df[\"annual_inc\"] < 200000],\n",
    "        height=10,\n",
    "        ratio=2,\n",
    "        space=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T01:43:08.401637Z",
     "iopub.status.busy": "2020-10-07T01:43:08.401155Z",
     "iopub.status.idle": "2020-10-07T01:43:08.418781Z",
     "shell.execute_reply": "2020-10-07T01:43:08.418290Z",
     "shell.execute_reply.started": "2020-10-07T01:43:08.401582Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Loan amount by Loan Verification status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.concat(\n",
    "    [\n",
    "        reverse_get_dummies(df, \"verification_status\").rename(\"verification_status\"),\n",
    "        df[[\"loan_amnt\", \"is_default\"]],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.barplot(\n",
    "    data=dfp, x=\"verification_status\", y=\"loan_amnt\", hue=\"is_default\", ax=ax, zorder=3\n",
    ")\n",
    "ax.grid(which=\"both\", axis=\"both\", color=\"lightgrey\", zorder=0)\n",
    "ax.legend(loc=\"best\", ncol=2, frameon=False)\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(None)\n",
    "ax.set_title(\n",
    "    \"Loan Amount versus Status of Loan Verification\", loc=\"left\", fontweight=\"bold\"\n",
    ")\n",
    "_ = customize_splines(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T01:43:08.401637Z",
     "iopub.status.busy": "2020-10-07T01:43:08.401155Z",
     "iopub.status.idle": "2020-10-07T01:43:08.418781Z",
     "shell.execute_reply": "2020-10-07T01:43:08.418290Z",
     "shell.execute_reply.started": "2020-10-07T01:43:08.401582Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Interest Rate by Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "(\n",
    "    pd.concat([reverse_get_dummies(df, \"term\").rename(\"term\"), df[\"int_rate\"]], axis=1)\n",
    ").boxplot(column=\"int_rate\", by=\"term\", ax=ax)\n",
    "ax.set_xlabel(None)\n",
    "fig.suptitle(None)\n",
    "_ = customize_splines(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan amount by Term of loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.concat(\n",
    "    [\n",
    "        reverse_get_dummies(df, \"term\").rename(\"term\"),\n",
    "        df[[\"loan_amnt\", \"is_default\"]],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.barplot(data=dfp, x=\"term\", y=\"loan_amnt\", hue=\"is_default\", ax=ax, zorder=3)\n",
    "ax.grid(which=\"both\", axis=\"both\", color=\"lightgrey\", zorder=0)\n",
    "ax.legend(loc=\"best\", ncol=2, frameon=False)\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(None)\n",
    "ax.set_title(\"Loan Amount versus Loan Term\", loc=\"left\", fontweight=\"bold\")\n",
    "_ = customize_splines(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly payments on debt obligations (excl. this loan) divided by monthly income by Open credit lines on file for borrower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.barplot(\n",
    "    data=pd.concat([df[[\"is_default\", \"open_acc\"]], dti_bin], axis=1),\n",
    "    x=\"dti_bin\",\n",
    "    y=\"open_acc\",\n",
    "    hue=\"is_default\",\n",
    "    ax=ax,\n",
    "    zorder=3,\n",
    ")\n",
    "ax.grid(which=\"both\", axis=\"both\", color=\"lightgrey\", zorder=0)\n",
    "ax.legend(loc=\"best\", ncol=2, frameon=False)\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(None)\n",
    "ax.set_title(\n",
    "    \"Open credit lines versus Monthly payments/monthly income\",\n",
    "    loc=\"left\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "_ = customize_splines(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest rate by Delinquency rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.barplot(\n",
    "    data=df,\n",
    "    x=\"delinq_2yrs\",\n",
    "    y=\"int_rate\",\n",
    "    hue=\"is_default\",\n",
    "    ax=ax,\n",
    "    zorder=3,\n",
    ")\n",
    "ax.grid(which=\"both\", axis=\"both\", color=\"lightgrey\", zorder=0)\n",
    "ax.legend(loc=\"best\", ncol=2, frameon=False)\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(None)\n",
    "ax.set_title(\n",
    "    \"Interest rate by Delinquency rate\",\n",
    "    loc=\"left\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "_ = customize_splines(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest Rate versus Loan Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.jointplot(\n",
    "        x=\"loan_amnt\",\n",
    "        y=\"int_rate\",\n",
    "        hue=\"is_default\",\n",
    "        data=df[df[\"loan_amnt\"] < 30000],\n",
    "        height=10,\n",
    "        ratio=2,\n",
    "        space=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest Rate versus Loan Amount for Zero and Non-zero public derogatory records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For zero public derogatory records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.jointplot(\n",
    "        x=\"loan_amnt\",\n",
    "        y=\"int_rate\",\n",
    "        hue=\"is_default\",\n",
    "        data=df[(df[\"pub_rec\"] == 0) & (df[\"loan_amnt\"] < 30000)],\n",
    "        height=10,\n",
    "        ratio=2,\n",
    "        space=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For non-zero derogatory records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.jointplot(\n",
    "        x=\"loan_amnt\",\n",
    "        y=\"int_rate\",\n",
    "        hue=\"is_default\",\n",
    "        data=df[(df[\"pub_rec\"] > 0) & (df[\"loan_amnt\"] < 30000)],\n",
    "        height=10,\n",
    "        ratio=2,\n",
    "        space=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature correlations between numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_consider_adding = [\n",
    "    \"grade\",\n",
    "    # \"sub_grade\",  # redundant if grade is also included\n",
    "    # \"issue_d\",  # date loan was funded; leaks data from future\n",
    "    \"addr_state\",  # will give 50 new dummy features\n",
    "    # \"recoveries\",  # recovery after charging off; leaks data from future\n",
    "    \"acc_now_delinq\",  # no. of accounts on which borrower is delinquent\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\n",
    "    \"loan_amnt\",  #\n",
    "    \"int_rate\",  #\n",
    "    \"emp_length\",  #\n",
    "    \"annual_inc\",  #\n",
    "    \"dti\",  #\n",
    "    \"delinq_2yrs\",  #\n",
    "    \"inq_last_6mths\",  #\n",
    "    \"open_acc\",  #\n",
    "    \"pub_rec\",  #\n",
    "    \"revol_bal\",  #\n",
    "    \"revol_util\",  #\n",
    "    \"fico_range_low\",  #\n",
    "    \"fico_range_high\",  #\n",
    "    \"installment\",  # dropped due to correlation\n",
    "    \"total_acc\",  # dropped due to correlation\n",
    "]\n",
    "categorical_cols = [\n",
    "    # does not seem to be ordinal\n",
    "    \"purpose\",\n",
    "    # # leaks data from future - DROP THIS\n",
    "    # \"last_fico_range\",\n",
    "    # rent, own, mortgage or other does not seem to be ordinal\n",
    "    \"home_ownership\",\n",
    "    # verified, not verified, or income source verified does not seem to be ordinal\n",
    "    \"verification_status\",\n",
    "    # consider label encoding (maybe an ordinal relationship)\n",
    "    \"term\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some labels to consider retaining are shown below\n",
    "- the objective here is to predict whether future loanees will default (label `1`) or not (label `0`)\n",
    "- this requires a model to have knowledge of past (**completed**) loans (ones that have been either fully paid back (label `0`) or defaulted (label `1`))\n",
    "  - a model cannot be trained on loans which are **not completed**, since these labels (`0` for a repaid loan, or `1` for a defaulted loan) are **not** known apriori.i.e. they are only known at some time in the future (after the loan application has been accepted or rejected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_consider_including_for_completed_loans = [\n",
    "    # following are completed loans (i.e. they are inactive)\n",
    "    \"Fully Paid\",  # is_default=0, loan_status=1 (currently included)\n",
    "    \"Charged Off\",  # is_default=1, loan_status=0 (currently included)\n",
    "    \"Default\",  # is_default=1\n",
    "    \"Late (16-30 days)\",  # is_default=1\n",
    "    \"Late (31-120 days)\"  # is_default=1\n",
    "    # following are not completed loans (i.e. they are still active)\n",
    "    \"Current\",  # cannot use\n",
    "    \"Issued\",  # cannot use\n",
    "    \"Does not meet the credit policy. Status:Fully Paid\",  # cannot use\n",
    "    \"In Grace Period\",  # cannot use\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_cols_reversed_dummies = pd.concat(\n",
    "#     [\n",
    "#         pd.concat(\n",
    "#             [reverse_get_dummies(df, col).rename(col) for col in categorical_cols],\n",
    "#             axis=1,\n",
    "#         ),\n",
    "#         df[numerical_cols],\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lower_corr_heatmap(\n",
    "    df[numerical_cols].corr(),\n",
    "    \"Correlation between numerical columns\",\n",
    "    1,\n",
    "    \".2f\",\n",
    "    0.975,\n",
    "    (10, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = df.corr().abs()\n",
    "sol = (\n",
    "    c.where(np.triu(np.ones(c.shape), k=1).astype(np.bool))\n",
    "    .stack()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "display(sol.reset_index().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        \"installment\",\n",
    "        \"loan_amnt\",\n",
    "        \"open_acc\",\n",
    "        \"total_acc\",\n",
    "        \"fico_range_low\",\n",
    "        \"fico_range_high\",\n",
    "    ]\n",
    "].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = [\"total_acc\", \"installment\", \"fico_range_low\", \"fico_range_high\"]\n",
    "look_ahead_features = [\"last_fico_range_low\", \"last_fico_range_high\"]\n",
    "df.drop(labels=correlated_features + look_ahead_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop `loan_status` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_labels = [\"loan_status\"]\n",
    "new_labels = [\"is_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=raw_labels, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFColumnDropper(TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        return X.drop(self.columns, axis=1)\n",
    "\n",
    "    def fit_transform(self, X, y=None, **kwargs):\n",
    "        self = self.fit(X, y)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline(\n",
    "#     [\n",
    "#         (\"label\", DFColumnDropper(raw_labels)),\n",
    "#     ]\n",
    "# )\n",
    "# df = pipe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline-based approach to add and remove columns from cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloud_storage == \"yes\":\n",
    "    az_storage_container_name = \"myconedesx7\"\n",
    "    conn_str = (\n",
    "        \"DefaultEndpointsProtocol=https;\"\n",
    "        f\"AccountName={os.getenv('AZURE_STORAGE_ACCOUNT')};\"\n",
    "        f\"AccountKey={os.getenv('AZURE_STORAGE_KEY')};\"\n",
    "        f\"EndpointSuffix={os.getenv('ENDPOINT_SUFFIX')}\"\n",
    "    )\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(conn_str=conn_str)\n",
    "\n",
    "    blobstrings = {}\n",
    "    for blob_name in [\"blobedesz38\"]:\n",
    "        blob_client = blob_service_client.get_blob_client(\n",
    "            container=az_storage_container_name, blob=blob_name\n",
    "        )\n",
    "        blobstring = blob_client.download_blob().content_as_text()\n",
    "    loans_2007 = pd.read_csv(StringIO(blobstring), skiprows=1, low_memory=False)\n",
    "else:\n",
    "    loans_2007 = pd.read_csv(raw_data_path, skiprows=1, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007, _ = train_test_split(loans_2007, test_size=0.33, random_state=4321)\n",
    "loans_2007 = loans_2007.reset_index(drop=True)\n",
    "df_reloaded = pipe_part_1_and_2.fit_transform(loans_2007)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll use a pipeline to\n",
    "- create the new column for labels and change its dtype to integers\n",
    "- drop correlated columns\n",
    "- drop the old labels column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"singlecolmap\", DFSingleColumnMapper(\"loan_status\", mapping_dict)),\n",
    "        (\"dtype\", DFSimpleDtypeChanger(new_labels, \"int\")),\n",
    "        (\"stdfilter\", DFColumnStdFilter(\"annual_inc\", 3)),\n",
    "        (\"corr\", DFColumnDropper(correlated_features)),\n",
    "        (\"lookahead\", DFColumnDropper(look_ahead_features)),\n",
    "        (\"label\", DFColumnDropper(raw_labels)),\n",
    "    ]\n",
    ")\n",
    "df_pipe = pipe.fit_transform(df_reloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_pipe.equals(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then use a pipeline to apply a different transformation to each numerical column in the dataset\n",
    "- this could also have been applied to all columns at once, or in groups of columns (if suitable groupings can be found such that all columns in each group are put through the same transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_transformers = {\n",
    "    \"loan_amnt\": Pipeline(steps=[(\"trans\", PowerTransformer(\"yeo-johnson\"))]),\n",
    "    \"int_rate\": Pipeline(steps=[(\"trans\", PowerTransformer(\"yeo-johnson\"))]),\n",
    "    # no transform for emp_length?\n",
    "    \"emp_length\": Pipeline(steps=[(\"trans\", PowerTransformer(\"yeo-johnson\"))]),\n",
    "    # for annual_inc, used box-cox since divide by 0 for yeo-johnson\n",
    "    \"annual_inc\": Pipeline(steps=[(\"trans\", PowerTransformer(\"yeo-johnson\"))]),\n",
    "    \"dti\": Pipeline(steps=[(\"trans\", PowerTransformer(\"yeo-johnson\"))]),\n",
    "    # no transform for delinq_2yrs?\n",
    "    \"delinq_2yrs\": Pipeline(steps=[(\"trans\", PowerTransformer(\"yeo-johnson\"))]),\n",
    "    # no transform for inq_last_6mths?\n",
    "    \"inq_last_6mths\": Pipeline(steps=[(\"trans\", PowerTransformer(\"yeo-johnson\"))]),\n",
    "    \"open_acc\": Pipeline(steps=[(\"trans\", PowerTransformer(\"yeo-johnson\"))]),\n",
    "    \"revol_bal\": Pipeline(steps=[(\"trans\", PowerTransformer(\"yeo-johnson\"))]),\n",
    "    # quantile transformation maybe preferred for revol_util?\n",
    "    \"revol_util\": Pipeline(\n",
    "        steps=[\n",
    "            (\n",
    "                \"trans\",\n",
    "                QuantileTransformer(\n",
    "                    n_quantiles=len(df_pipe), output_distribution=\"normal\"\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "# need passthrough to retain the following columns: [\"pub_rec\"]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(k, v, [k]) for k, v in col_transformers.items()],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "pipe_trans = Pipeline([(\"preprocessor\", preprocessor)])\n",
    "df_trans = pd.DataFrame(pipe_trans.fit_transform(df), columns=list(df))\n",
    "df_trans_pipe = pd.DataFrame(pipe_trans.fit_transform(df_pipe), columns=list(df_pipe))\n",
    "display(df_trans.head(2))\n",
    "display(df_trans_pipe.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since early all transformations are power transformers, it may be more convenient to use this for the last column as well. Such an approach would be easier to maintain as the number of numeric features is varied during further analysis. This strategy will be used in subsequent steps of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_trans.shape)\n",
    "print(df_trans_pipe.shape)\n",
    "assert df_trans.equals(df_trans_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check column data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, we should not have any non-numeric columns in the processed data that will be passed to modeling algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_trans_pipe.select_dtypes(include=[\"object\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should only have numerical columns, and that is indeed the case here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_pipe.dtypes.to_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
