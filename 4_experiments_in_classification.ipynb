{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mr\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    RepeatedKFold,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.custom_transformers\n",
    "import src.custom_transformers as ct\n",
    "\n",
    "%aimport src.ml_helpers\n",
    "from src.ml_helpers import base_pipeline, multi_model_grid_search\n",
    "\n",
    "%aimport src.ml_metrics\n",
    "from src.ml_metrics import (\n",
    "    recall_binary_scorer,\n",
    "    threshold_fpr_score,\n",
    "    threshold_recall_score,\n",
    "    threshold_auc_score,\n",
    ")\n",
    "\n",
    "%aimport src.visualization_helpers\n",
    "from src.visualization_helpers import (\n",
    "    plot_learning_curve,\n",
    "    builtin_plot_permutation_importances,\n",
    "    plot_cross_validated_coefs,\n",
    "    show_yb_grid,\n",
    "    plot_grouped_bar_chart,\n",
    "    plot_grouped_histogram,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk through machine learning classification experiments on the raw [Lending Club loans data](https://www.lendingclub.com/auth/login?login_url=%2Fstatistics%2Fadditional-statistics%3F). A best-performing model will then be determined and assessed in the context of the business use case for this project.i.e. an conservative investor wanting to use the model developed here to predict which loan applications on the [Lending Club platform](https://www.lendingclub.com/), will not [default](https://en.wikipedia.org/wiki/Default_(finance)), and therefore should be funded by them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User inputs and helper functions, to be used later, are defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "raw_data_file_path = \"data/raw/lending_club_loans.csv\"\n",
    "cloud_storage = \"no\"\n",
    "\n",
    "# From Feature Reduction\n",
    "nan_threshold = 0.5\n",
    "non_useful_cols = [\"url\", \"desc\"]\n",
    "datetime_cols = [\"issue_d\", \"last_pymnt_d\"]\n",
    "cols_one_eighteen = [\n",
    "    \"id\",\n",
    "    \"member_id\",\n",
    "    \"funded_amnt\",\n",
    "    \"funded_amnt_inv\",\n",
    "    \"grade\",\n",
    "    \"sub_grade\",\n",
    "    \"emp_title\",\n",
    "]\n",
    "cols_eighteen_thirtysix = [\n",
    "    \"zip_code\",\n",
    "    \"out_prncp\",\n",
    "    \"out_prncp_inv\",\n",
    "    \"total_pymnt\",\n",
    "    \"total_pymnt_inv\",\n",
    "    \"total_rec_prncp\",\n",
    "]\n",
    "cols_thirtyseven_end = [\n",
    "    \"total_rec_int\",\n",
    "    \"total_rec_late_fee\",\n",
    "    \"recoveries\",\n",
    "    \"collection_recovery_fee\",\n",
    "    \"last_pymnt_amnt\",\n",
    "]\n",
    "loan_status = [\"Fully Paid\", \"Charged Off\"]\n",
    "mapping_dictionary_labels = {\"loan_status\": {\"Fully Paid\": 1, \"Charged Off\": 0}}\n",
    "four_or_less_value_columns = [\"pymnt_plan\"]\n",
    "\n",
    "# From Feature Processing\n",
    "more_than_one_pct_missing_columns = [\"pub_rec_bankruptcies\"]\n",
    "datetime_cols_v2 = [\"last_credit_pull_d\", \"earliest_cr_line\"]\n",
    "high_cardinality_cols = [\"addr_state\"]\n",
    "mapping_dict_emp_length = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0,\n",
    "    }\n",
    "}\n",
    "nominal_columns = [\"home_ownership\", \"verification_status\", \"purpose\", \"term\"]\n",
    "repeated_data_cols = [\"title\"]\n",
    "pct_to_numeric_cols = [\"int_rate\", \"revol_util\"]\n",
    "\n",
    "# From Exploratory Data Analysis 1/2\n",
    "correlated_features = [\n",
    "    # \"total_acc\",\n",
    "    \"installment\",\n",
    "    \"fico_range_low\",\n",
    "    \"fico_range_high\",\n",
    "]\n",
    "look_ahead_features = [\"last_fico_range_low\", \"last_fico_range_high\"]\n",
    "raw_labels = [\"loan_status\"]\n",
    "new_labels = [\"is_default\"]\n",
    "\n",
    "cols_to_show = [\n",
    "    \"preprocessor_type\",\n",
    "    \"resamplers\",\n",
    "    \"clf\",\n",
    "    \"threshold\",\n",
    "    \"params\",\n",
    "    \"mean_test_recall_binary\",\n",
    "    \"mean_test_fpr\",\n",
    "    \"mean_test_auc\",\n",
    "    \"mean_train_recall_binary\",\n",
    "    \"mean_train_fpr\",\n",
    "    \"mean_train_auc\",\n",
    "    \"mean_fit_time\",\n",
    "    \"std_train_recall_binary\",\n",
    "    \"std_test_recall_binary\",\n",
    "    \"std_train_fpr\",\n",
    "    \"std_test_fpr\",\n",
    "    \"mean_score_time\",\n",
    "    \"clf_params\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_threshold = float(nan_threshold)\n",
    "for k in [\"Fully Paid\", \"Charged Off\"]:\n",
    "    mapping_dictionary_labels[\"loan_status\"][k] = int(\n",
    "        mapping_dictionary_labels[\"loan_status\"][k]\n",
    "    )\n",
    "for k in [\n",
    "    \"10+ years\",\n",
    "    \"9 years\",\n",
    "    \"8 years\",\n",
    "    \"7 years\",\n",
    "    \"6 years\",\n",
    "    \"5 years\",\n",
    "    \"4 years\",\n",
    "    \"3 years\",\n",
    "    \"2 years\",\n",
    "    \"1 year\",\n",
    "    \"< 1 year\",\n",
    "    \"n/a\",\n",
    "]:\n",
    "    mapping_dict_emp_length[\"emp_length\"][k] = int(\n",
    "        mapping_dict_emp_length[\"emp_length\"][k]\n",
    "    )\n",
    "\n",
    "# From Exploratory Data Analysis 2/2\n",
    "mapping_dict_new_labels = {\"is_default\": {0: 1, 1: 0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw data from Lending Club is loaded into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloud_storage == \"yes\":\n",
    "    az_storage_container_name = \"myconedesx7\"\n",
    "    conn_str = (\n",
    "        \"DefaultEndpointsProtocol=https;\"\n",
    "        f\"AccountName={os.getenv('AZURE_STORAGE_ACCOUNT')};\"\n",
    "        f\"AccountKey={os.getenv('AZURE_STORAGE_KEY')};\"\n",
    "        f\"EndpointSuffix={os.getenv('ENDPOINT_SUFFIX')}\"\n",
    "    )\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(conn_str=conn_str)\n",
    "\n",
    "    blobstrings = {}\n",
    "    for blob_name in [\"blobedesz38\"]:\n",
    "        blob_client = blob_service_client.get_blob_client(\n",
    "            container=az_storage_container_name, blob=blob_name\n",
    "        )\n",
    "        blobstring = blob_client.download_blob().content_as_text()\n",
    "    df = pd.read_csv(StringIO(blobstring), skiprows=1, low_memory=False)\n",
    "else:\n",
    "    df = pd.read_csv(raw_data_file_path, skiprows=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hold-out set of the raw data will be set aside for model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.33, random_state=4321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data is cleaned, filtered and features are extracted/selected from this processed data in order to run experiments in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1_2_3 = Pipeline(\n",
    "    [\n",
    "        # nan_threshold=0.5, is a float in [0, 1.0] - CAN CHANGE OR KEEP UNCHANGED\n",
    "        (\"nanthresh\", ct.DFNanThresholdColumnDropper(0.5)),\n",
    "        (\"nouse\", ct.DFColumnDropper(non_useful_cols)),\n",
    "        (\"dtime\", ct.DFColumnDropper(datetime_cols)),\n",
    "        (\"c1\", ct.DFColumnDropper(cols_one_eighteen)),\n",
    "        (\"c2\", ct.DFColumnDropper(cols_eighteen_thirtysix)),\n",
    "        (\"c3\", ct.DFColumnDropper(cols_thirtyseven_end)),\n",
    "        (\n",
    "            \"mapstatus\",\n",
    "            ct.DFColumnFilterList(\"loan_status\", loan_status),\n",
    "        ),\n",
    "        (\"colmap\", ct.DFColumnMapper(mapping_dictionary_labels)),\n",
    "        (\"onevals\", ct.DFNonUniqueValColDropper(num_non_unique_vals=1)),\n",
    "        # four_or_less_value_columns=['pymnt_plan'] - 'pymnt_plan' is MOSTLY 'n', EXCLUDE\n",
    "        (\"fourvals\", ct.DFColumnDropper(four_or_less_value_columns)),\n",
    "        # more_than_one_pct_missing_columns = ['pub_rec_bankruptcies']\n",
    "        (\"morethan1pctnan\", ct.DFColumnDropper(more_than_one_pct_missing_columns)),\n",
    "        (\"nan\", ct.DFDropNaN()),\n",
    "        # high_cardinality_cols=['addr_state'] - CAN INCLUDE OR EXCLUDE\n",
    "        (\"hcardcols\", ct.DFColumnDropper(high_cardinality_cols)),\n",
    "        (\"dtimev2\", ct.DFColumnDropper(datetime_cols_v2)),\n",
    "        (\"texttonum\", ct.DFColumnMapper(mapping_dict_emp_length)),\n",
    "        (\"repeats\", ct.DFColumnDropper(repeated_data_cols)),\n",
    "        (\"pctcols\", ct.DFPctNumeric(pct_to_numeric_cols, \"%\")),\n",
    "        (\n",
    "            \"singlecolmap\",\n",
    "            ct.DFSingleColumnMapper(\"loan_status\", mapping_dict_new_labels),\n",
    "        ),\n",
    "        (\"dtype\", ct.DFSimpleDtypeChanger(new_labels, \"int\")),\n",
    "        # n_std is an integer - CAN CHANGE OR KEEP UNCHANGED\n",
    "        (\"stdfilter\", ct.DFColumnStdFilter(\"annual_inc\", 3)),\n",
    "        # correlated_features=['total_acc','installment','fico_range_low','fico_range_high'] EXCLUDE\n",
    "        (\"corr\", ct.DFColumnDropper(correlated_features)),\n",
    "        (\"lookahead\", ct.DFColumnDropper(look_ahead_features)),\n",
    "        (\"label\", ct.DFColumnDropper(raw_labels)),\n",
    "        # requires (\"corr\", ...) to be removed; threshold=1, ideally chosen from dendogram\n",
    "        # (\"clusterselect\", ct.DFHierarchicalClusterSpearmanRank(threshold=1)),\n",
    "    ]\n",
    ")\n",
    "df_pipe_transformed_train = pipe_1_2_3.fit_transform(df_train)\n",
    "df_pipe_transformed_test = pipe_1_2_3.transform(df_test)\n",
    "print(df_pipe_transformed_train.shape)\n",
    "print(df_pipe_transformed_test.shape)\n",
    "display(df_pipe_transformed_train.head(2))\n",
    "display(df_pipe_transformed_test.head(2))\n",
    "display(df_pipe_transformed_train[\"is_default\"].squeeze().value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features and class labels from processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features and labels are now extracted from the processed training and testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_pipe_transformed_train.drop(labels=new_labels, axis=1)\n",
    "y_train = df_pipe_transformed_train[new_labels].astype(int).squeeze()\n",
    "X_test = df_pipe_transformed_test.drop(labels=new_labels, axis=1)\n",
    "y_test = df_pipe_transformed_test[new_labels].astype(int).squeeze()\n",
    "display(X_train.head(2))\n",
    "display(X_test.head(2))\n",
    "display(y_train.to_frame().head(2))\n",
    "display(y_test.to_frame().head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble components for `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline inputs and other components required for hyperparameter optimization using `GridSearchCV` are extracted here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists of features by type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of numerical and categorical features is extracted from the processed data\n",
    "- numerical features are those with a datatype of `float`\n",
    "- categorical features are those that do not have a datatype of `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    c\n",
    "    for c in list(X_train.select_dtypes(exclude=\"object\"))\n",
    "    if c not in new_labels + [\"emp_length\"]\n",
    "]\n",
    "nominal_columns = list(X_train.select_dtypes(include=\"object\")) + [\"emp_length\"]\n",
    "try:\n",
    "    assert set(numerical_columns + nominal_columns) == set(list(X_train)) - set(\n",
    "        new_labels\n",
    "    )\n",
    "    print(\"Columns from training data match feature lists\")\n",
    "except AssertionError as e:\n",
    "    print(\"Some columns from training data are missing from feature lists\")\n",
    "print(\"Categoricals:\\n-\" + \"\\n-\".join(nominal_columns))\n",
    "print(\"Numericals:\\n-\" + \"\\n-\".join(numerical_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, feature transformations to be applied to all numerical columns are defined. With or without transformations, all numerical features will be normalized. All categorical features will be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_transformers = {\n",
    "    c: Pipeline(\n",
    "        steps=[\n",
    "            (\"trans\", ct.DFPowerTransformer(\"yeo-johnson\")),\n",
    "            (\"ss\", ct.DFStandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "    for c in numerical_columns\n",
    "}\n",
    "preprocessors = {\n",
    "    \"no_trans\": ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\n",
    "                \"nums\",\n",
    "                Pipeline(steps=[(\"trans\", StandardScaler())]),\n",
    "                numerical_columns,\n",
    "            )\n",
    "        ]\n",
    "        + [(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), nominal_columns)],\n",
    "        remainder=\"passthrough\",\n",
    "    ),\n",
    "    \"trans\": ColumnTransformer(\n",
    "        transformers=[(k, v, [k]) for k, v in col_transformers.items()]\n",
    "        + [(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), nominal_columns)],\n",
    "        remainder=\"passthrough\",\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers and hyper-parameters for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models to be compared, discrimination threshold(s) (to be applied to all listed models), and dictionaries of model hyper-parameters for tuning, are defined below\n",
    "- for hyper-parameter dictionaries containing cost-function weights, for manual specification of the penalties used in the algorithm's cost function, the larger penalty should be assigned to the minority class (see [**Lesson 07. Cost-Sensitive Algorithms**](https://machinelearningmastery.com/imbalanced-classification-with-python-7-day-mini-course/))\n",
    "  - here, this is for the positive class where `is_default`==1, and is explicitly shown below through the class-balance of the labels from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_list = [\n",
    "    # DummyClassifier(strategy=\"stratified\", random_state=42),\n",
    "    LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=500),\n",
    "    # RandomForestClassifier(n_jobs=-1, random_state=42),\n",
    "    # AdaBoostClassifier(random_state=42),\n",
    "    # GaussianNB(),\n",
    "    # BernoulliNB(),\n",
    "]\n",
    "thresholds = [0.4, 0.5]\n",
    "parameters = {\n",
    "    \"DummyClassifier\": {\"strategy\": [\"stratified\", \"most_frequent\", \"uniform\"]},\n",
    "    \"LogisticRegression\": {\n",
    "        \"C\": [1.0],\n",
    "        \"class_weight\": [\n",
    "            \"balanced\",\n",
    "            {0: 1, 1: 5},\n",
    "        ],\n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"n_estimators\": [500],\n",
    "        \"min_samples_split\": [10],\n",
    "        \"class_weight\": [{0: 1, 1: 5}, \"balanced\"],\n",
    "    },\n",
    "    \"AdaBoostClassifier\": {\"n_estimators\": [500]},\n",
    "    \"GaussianNB\": {\"priors\": [None]},\n",
    "    \"BernoulliNB\": {\"fit_prior\": [True, False], \"class_prior\": [None]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installment, total_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run `GridSearchCV` without transformed features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameter optimization is performed without numerical feature transformations\n",
    "- normalization (numerical) and one-hot encoding (categorical) are applied to the features before classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, this is done while varying the discrimination threshold, including the default threshold of `0.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs_summary_no_trans = multi_model_grid_search(\n",
    "    clf_list, X_train, y_train, preprocessors, parameters, thresholds, False, \"no_trans\"\n",
    ")[cols_to_show]\n",
    "display(df_gs_summary_no_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, this is done without varying the discrimination threshold, and so only uses the default threshold of `0.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs_summary_no_trans_no_custom_threshold = multi_model_grid_search(\n",
    "    clf_list, X_train, y_train, preprocessors, parameters, [], True, \"no_trans\"\n",
    ")[cols_to_show]\n",
    "display(df_gs_summary_no_trans_no_custom_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it is shown that, for the case of a default threshold of `0.5`, both approaches are equivalent. So, the approach of varying the discrimination threshold, for non-default values higher or lower than `0.5`, can be used in further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert (\n",
    "        df_gs_summary_no_trans[df_gs_summary_no_trans[\"threshold\"] == 0.5]\n",
    "        .reset_index(drop=True)\n",
    "        .drop(columns=[\"mean_fit_time\", \"mean_score_time\"], axis=1)\n",
    "    ).equals(\n",
    "        df_gs_summary_no_trans_no_custom_threshold.drop(\n",
    "            columns=[\"mean_fit_time\", \"mean_score_time\"], axis=1\n",
    "        )\n",
    "    )\n",
    "except AssertionError as e:\n",
    "    print(\n",
    "        \"Disagreement between threshold sensitive and threshold agnostic \"\n",
    "        \"approaches for default discrimination threshold of 0.5.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"Agreement between threshold sensitive and threshold agnostic \"\n",
    "        \"approaches for default discrimination threshold of 0.5.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run `GridSearchCV` with transformed features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameter optimization is performed with numerical feature transformations\n",
    "- normalization (numerical) and one-hot encoding (categorical) are applied to the features before classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs_summary_trans = multi_model_grid_search(\n",
    "    clf_list, X_train, y_train, preprocessors, parameters, thresholds, False, \"trans\"\n",
    ")[cols_to_show]\n",
    "display(df_gs_summary_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of multi-model `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined results of the multi-model hyperparameter optimization, with and without feature transformations, are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs_summary = (\n",
    "    pd.concat([df_gs_summary_trans, df_gs_summary_no_trans])\n",
    "    .sort_values(\n",
    "        by=[\"mean_test_recall_binary\", \"mean_test_fpr\", \"mean_test_auc\"],\n",
    "        ascending=[False, True, False],\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "display(df_gs_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. The best `TPR` and `FPR` are approximately 66% and 39% respectively. If both types of loans are arbitrarily funded, the relative benefit of the higher `TPR` is that the best model found here will be better at avoiding loans that result in a default (and loss of money) at the expense of not allowing 34% of the total available loans that will not default (`FPR`) to be funded. These (`FPR`, 34%) are missed opportunities to earn returns and there is a stronger case for the `TPR` (64%) to be higher, than for the `FPR` to be lower, and thus save the business user (a risk-averse investor) money. In practice, further discussion with the end user (the investor) is warranted in order to determine their risk tolerance before picking between these two metrics.\n",
    "2. (Training or validation) Scores with and without feature transformations are minimally different.\n",
    "3. Since a shorter duration is required for training without transformations, a pipeline with no feature transformations (`preprocessor_type=\"no_trans\"`) will be selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract components of best pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the following four components of the pipelines tried\n",
    "- name of model\n",
    "- model hyper-parameters\n",
    "- type of preprocessor\n",
    "- discrimination threshold\n",
    "\n",
    "are extracted from the best chosen pipeline, while keeping in mind the objectives of the business use case (i.e. maximize recall, minimize `FPR`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cfg_idx = df_gs_summary[\n",
    "    (df_gs_summary[\"preprocessor_type\"] == \"no_trans\")\n",
    "    & (df_gs_summary[\"clf\"] == \"LogisticRegression\")\n",
    "    & df_gs_summary[\"params\"].astype(str).str.contains(\"'balanced'\")\n",
    "    & (df_gs_summary[\"threshold\"] == 0.5)\n",
    "].index[0]\n",
    "print(f\"Best pipeline configuration occurs at row index: {best_cfg_idx}\")\n",
    "display(df_gs_summary.loc[best_cfg_idx].to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the extracted pipeline components are assigned to variables for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    best_clf_name,\n",
    "    best_pipe_params_dict,\n",
    "    best_threshold,\n",
    "    best_preprocessor_type,\n",
    ") = df_gs_summary.loc[\n",
    "    best_cfg_idx, [\"clf\", \"params\", \"threshold\", \"preprocessor_type\"]\n",
    "].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble best pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new pipeline is instantiated using the extracted\n",
    "- model\n",
    "- model hyper-parameters\n",
    "- preprocessor\n",
    "\n",
    "from the best pipeline chosen above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe_params_dict = {k.split(\"__\")[1]: v for k, v in best_pipe_params_dict.items()}\n",
    "best_pipe_params_dict.update(dict(penalty=\"l2\", solver=\"lbfgs\", max_iter=500))\n",
    "clf = LogisticRegression(**best_pipe_params_dict)\n",
    "pipe = base_pipeline(preprocessors[best_preprocessor_type])\n",
    "pipe.steps.append([\"clf\", clf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New scorers are instantiated using the extracted discrimination threshold from the best pipeline chosen above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_scorers = {\n",
    "    \"recall_binary\": mr.make_scorer(\n",
    "        threshold_recall_score,\n",
    "        greater_is_better=True,\n",
    "        needs_proba=True,\n",
    "        threshold=best_threshold,\n",
    "    ),\n",
    "    \"fpr\": mr.make_scorer(\n",
    "        threshold_fpr_score,\n",
    "        greater_is_better=False,\n",
    "        needs_proba=True,\n",
    "        threshold=best_threshold,\n",
    "    ),\n",
    "    \"auc\": mr.make_scorer(\n",
    "        threshold_auc_score,\n",
    "        greater_is_better=True,\n",
    "        needs_proba=True,\n",
    "        threshold=best_threshold,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best pipeline assembled above is trained on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerical_columns, nominal_columns, list(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metrics on the held-out data are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"test\": {\n",
    "            \"recall_binary\": threshold_recall_score(\n",
    "                y_test, pipe.predict_proba(X_test)[:, 1], 0.5\n",
    "            ),\n",
    "            \"fpr\": -1\n",
    "            * threshold_fpr_score(y_test, pipe.predict_proba(X_test)[:, 1], 0.5),\n",
    "            \"auc\": threshold_auc_score(y_test, pipe.predict_proba(X_test)[:, 1], 0.5),\n",
    "        },\n",
    "        \"train\": {\n",
    "            \"recall_binary\": threshold_recall_score(\n",
    "                y_train, pipe.predict_proba(X_train)[:, 1], 0.5\n",
    "            ),\n",
    "            \"fpr\": -1\n",
    "            * threshold_fpr_score(y_train, pipe.predict_proba(X_train)[:, 1], 0.5),\n",
    "            \"auc\": threshold_auc_score(y_train, pipe.predict_proba(X_train)[:, 1], 0.5),\n",
    "        },\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A grid of diagnostic plots are shown below for predictions, using the best pipeline found above, on OOS data (the test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_yb_grid(\n",
    "    pipe,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    np.sort(y_test.unique()),\n",
    "    pd.concat([X_train, X_test]),\n",
    "    pd.concat([y_train, y_test]),\n",
    "    StratifiedKFold(n_splits=5, shuffle=False),\n",
    "    np.round(np.arange(0, 1.1, 0.1), 3),\n",
    "    wspace=0.1,\n",
    "    hspace=0.3,\n",
    "    fig_size=(12, 12),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. The per-class ROC curve is computed on the held-out data only and, by definition, is not sensitive to changes in discrimination threshold.\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For examining the importance of features (columns), cross-validation could be performed on the full data set (combined training and testing splits), as shown below. Multiple OOS splits are used and the average model coefficient, for each feature, across all splits would be taken as being indicative of overall OOS performance\n",
    "- NOTE: metrics (`TPR` and `FPR`) computed on in-sample and held-out splits are computed but are not used in this plot; instead, only the model coefficients for each feature are extracted for each split and shown on the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cross_validated_coefs(\n",
    "    pipe,\n",
    "    numerical_columns,\n",
    "    nominal_columns,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    multi_scorers,\n",
    "    n_repeats=5,\n",
    "    n_splits=5,\n",
    "    axis_tick_label_fontsize=12,\n",
    "    fig_size=(8, 12),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. From this graph, the one-hot encoded version of the features are shown. Ideally, the reverse-encoded feature would be shown since that is how it appears in the data.\n",
    "2. Problems with using such coefficients/importances of a modeling algorithm include\n",
    "   - incorrect normalization of the data during pre-processing\n",
    "   - incorrectly, or not at all, accounting for the influence of highly-correlated features on model coefficients/importances during\n",
    "     - the modeling process\n",
    "       - these problems are specific to each model\n",
    "     - [interpretation of model coefficients](https://projecteuclid.org/euclid.ss/1009213726)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-Neutral Permutation Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In permutation importance ([1](https://academic.oup.com/bioinformatics/article/26/10/1340/193348), [2](https://docs.cloud.oracle.com/en-us/iaas/tools/ads-sdk/latest/user_guide/mlx/permutation_importance.html#description)), each column is iteratively randomized and used as an input for modeling. The difference in scoring metric with and without this randomization is taken as the importance of the column being randomized to the model. This process is repeated for each column individually. It provides a model agnostic indication of the importance of each feature, independent of how the algorithm's coefficients/importances are computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a boxplot highlighting the impact on model performance, using `TPR` as the scoring metric, of randomizing columns from the data individually (i.e. as determined using permutation importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_permutation_importances(\n",
    "    pipe,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    scorer=multi_scorers[\"recall_binary\"],\n",
    "    n_repeats=10,\n",
    "    wspace=0.4,\n",
    "    fig_title_fontsize=16,\n",
    "    fig_title_vertical_pos=0.97,\n",
    "    axis_tick_label_fontsize=12,\n",
    "    box_color=\"cyan\",\n",
    "    fig_size=(12, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a boxplot highlighting the impact on model performance, using `FPR` as the scoring metric, as determined using permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_permutation_importances(\n",
    "    pipe,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    scorer=multi_scorers[\"fpr\"],\n",
    "    n_repeats=10,\n",
    "    wspace=0.4,\n",
    "    fig_title_fontsize=16,\n",
    "    fig_title_vertical_pos=0.97,\n",
    "    axis_tick_label_fontsize=12,\n",
    "    box_color=\"cyan\",\n",
    "    fig_size=(12, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check of bias and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias and variance related to this dataset are explored below, in terms of `TPR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(\n",
    "    pipe,\n",
    "    f\"Learning Curves for {type(pipe.named_steps['clf']).__name__}\",\n",
    "    X=pd.concat([X_train.iloc[:, :], X_test.iloc[:, :]]).reset_index(drop=True),\n",
    "    y=pd.concat([y_train[:], y_test[:]]).reset_index(drop=True),\n",
    "    cv=RepeatedKFold(n_splits=5, n_repeats=5, random_state=42),\n",
    "    scorer=multi_scorers[\"recall_binary\"],\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "    legend_coords=(0.7, 1),\n",
    "    axis_tick_label_fontsize=12,\n",
    "    fig_size=(8, 12),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias and variance related to this dataset are explored below, in terms of `FPR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(\n",
    "    pipe,\n",
    "    f\"Learning Curves for {type(pipe.named_steps['clf']).__name__}\",\n",
    "    X=pd.concat([X_train.iloc[:, :], X_test.iloc[:, :]]).reset_index(drop=True),\n",
    "    y=pd.concat([y_train[:], y_test[:]]).reset_index(drop=True),\n",
    "    cv=RepeatedKFold(n_splits=5, n_repeats=5, random_state=42),\n",
    "    scorer=multi_scorers[\"fpr\"],\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "    legend_coords=(0.7, 1),\n",
    "    axis_tick_label_fontsize=12,\n",
    "    fig_size=(8, 12),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. The permutation importance (previous sub-section) and learning curve plotting codes used here are not sensitive to discrimination threshold and pick a default value of 0.5. However, since the best configuration used a threshold of 0.5, these plotting codes are used as-is. If a different threshold value were chosen, these plots would have to be generated manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Assessing bias\n",
    "   - high validation and training errors indicate a high bias problem.\n",
    "2. Assessing variance\n",
    "   - a low training error and large gap would indicate overfitting and collecting more data is one approach to attempt at rectifying this problem - however, this is not the case here for the best model found above. High training error and a low gap between training and validation errors indicate a low variance problem.\n",
    "3. Combined, this indicates that the best model is underfitting the training data. Adding data is unlikely to remedy this problem.\n",
    "4. Further work should focus on extracting more features from the dataset - currently only a single feature `is_employed` (a binary feature indicating whether the applicant was employed or not at the time of applying for the loan on Lending Club) was extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring incorrect predictions from the held-out data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an exploration of predictions, from the unseen data, that the model got incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join dropped columns with held-out data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore misclassifications by grouping across a column not used in modeling, such as `addr_state`, the held-out data is merged with the raw data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.Series(pipe.predict(X_test), index=X_test.index, name=\"pred\")\n",
    "df_tp = df[[\"addr_state\"]].merge(\n",
    "    pd.concat(\n",
    "        [\n",
    "            X_test[\n",
    "                [\n",
    "                    \"purpose\",\n",
    "                    \"home_ownership\",\n",
    "                    \"emp_length\",\n",
    "                    \"term\",\n",
    "                ]\n",
    "                + numerical_columns\n",
    "            ],\n",
    "            y_test,\n",
    "            y_pred,\n",
    "        ],\n",
    "        axis=1,\n",
    "    ),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `misclassified` column is appended to the merged data in order to indicate a mis-match between the true and predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tp[\"misclassified\"] = df_tp[\"is_default\"] != df_tp[\"pred\"]\n",
    "display(df_tp)\n",
    "display(df_tp.dtypes.to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in numerical_columns:\n",
    "    plot_grouped_histogram(df_tp, c, (0.675, 1.1), 0.5, 0.15, (12, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. For the chosen numerical columns, the distributions of correctly and incorrectly predicted loan status are similar to eachother and follow that of the overall (true) held-out data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, wspace, fig_size in zip(\n",
    "    [\"home_ownership\", \"purpose\", \"emp_length\", \"term\", \"addr_state\"],\n",
    "    [0.25, 0.4, 0.1, 0.25, 0.1],\n",
    "    [(12, 4), (12, 4), (12, 4), (12, 4), (12, 8)],\n",
    "):\n",
    "    plot_grouped_bar_chart(df_tp, col, \"misclassified\", wspace, fig_size=fig_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. For the `Term` column of the data\n",
    "   - although nearly 75% of the loans (RHS plot) required 36 monthly payments, the model found here has nearly the same difficulty (LHS plot) predicting loans requiring 36 or 60 monthly payments. The model has trouble with predicting infrequently occurring term loans (60 months) than those that occur more commonly (36 months).\n",
    "2. In terms of the `Employment Length` and `Purpose` columns of the data, the incorrect model predictions follow the frequency of the data - more commonly occurring categories in each of these columns are misclassified.\n",
    "3. The model has greater difficulty (45% misclassifications, LHS plot) in predicting the outcome for home owners who pay `Rent` than what is observed from the data (40%, RHS plot)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model found here returns a `FPR` of approximately 34% and a `TPR` of approximately 65%. Since a conservative investor would want the `FPR` to be lowered before deploying this model to determine if new loan applications hould be funded, in order to avoid funding riskier loans (ones that will default), further iterations of this project should focus on the following\n",
    "- extracting more machine learning features from the raw Lending Club data\n",
    "  - consider a less stringent threshold (currently 50%) for dropping features with missing data\n",
    "    - this could possibly re-introduce some features into the dataset that hopefully add predictive power to the models tried\n",
    "  - based on incorrect model predictions, further exploration (incl. outlier removal) of the home ownership and loan term columns from the data may be warranted\n",
    "- additional model hyper-parameter, incl. threshold, optimization\n",
    "- other techniques to remove outliers from features (currently filtering, based on univariate visualization, was used) in the dataset before machine learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
