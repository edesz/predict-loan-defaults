{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Reduction - Eliminating unwanted columns manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.custom_transformers\n",
    "from src.custom_transformers import (\n",
    "    DFNanThresholdColumnDropper,\n",
    "    DFColumnDropper,\n",
    "    DFColumnFilterList,\n",
    "    DFColumnMapper,\n",
    "    DFNonUniqueValColDropper,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by removing columns from the data that can't be used in analysis for a variety of reasons (summarized here). Details about the columns are available [here](https://www.rubydoc.info/gems/lending_club/0.0.2/LendingClub/Loan)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input values are defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "raw_data_path = \"data/raw/lending_club_loans.csv\"\n",
    "cloud_storage = \"no\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloud_storage == \"yes\":\n",
    "    az_storage_container_name = \"myconedesx7\"\n",
    "    conn_str = (\n",
    "        \"DefaultEndpointsProtocol=https;\"\n",
    "        f\"AccountName={os.getenv('AZURE_STORAGE_ACCOUNT')};\"\n",
    "        f\"AccountKey={os.getenv('AZURE_STORAGE_KEY')};\"\n",
    "        f\"EndpointSuffix={os.getenv('ENDPOINT_SUFFIX')}\"\n",
    "    )\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(conn_str=conn_str)\n",
    "\n",
    "    blobstrings = {}\n",
    "    for blob_name in [\"blobedesz38\"]:\n",
    "        blob_client = blob_service_client.get_blob_client(\n",
    "            container=az_storage_container_name, blob=blob_name\n",
    "        )\n",
    "        blobstring = blob_client.download_blob().content_as_text()\n",
    "    loans_2007 = pd.read_csv(StringIO(blobstring), skiprows=1, low_memory=False)\n",
    "else:\n",
    "    loans_2007 = pd.read_csv(raw_data_path, skiprows=1, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aside 33% as test data\n",
    "loans_2007, _ = train_test_split(loans_2007, test_size=0.33, random_state=4321)\n",
    "loans_2007 = loans_2007.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual feature reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll manually eliminate certain columns that are either\n",
    "- unusable for modeling purposes, such as ZIP code\n",
    "- populated after a single loan record is created\n",
    "  - this is fine for record-keeping purposes, but since they cannot be known until some time after the loan begins to be funded/paid off they cannot be used to *predict* whether the corresponding loan will be paid off on time or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns missing more than half of their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns not used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_useful_cols = [\"url\", \"desc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns with a date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_cols = [\"issue_d\", \"last_pymnt_d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First group of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DFNanThresholdColumnDropper(TransformerMixin):\n",
    "#     def __init__(self, threshold):\n",
    "#         self.threshold = threshold\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         # assumes X is a DataFrame\n",
    "#         return X.dropna(thresh=self.threshold * len(X), axis=1)\n",
    "\n",
    "#     def fit_transform(self, X, y=None, **kwargs):\n",
    "#         self = self.fit(X, y)\n",
    "#         return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DFColumnDropper(TransformerMixin):\n",
    "#     def __init__(self, columns):\n",
    "#         self.columns = columns\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         # assumes X is a DataFrame\n",
    "#         cols_to_drop = []\n",
    "#         for c in list(X):\n",
    "#             for cd in self.columns:\n",
    "#                 if cd in c:\n",
    "#                     cols_to_drop.append(cd)\n",
    "#         if cols_to_drop:\n",
    "#             return X.drop(cols_to_drop, axis=1)\n",
    "#         else:\n",
    "#             return X\n",
    "\n",
    "#     def fit_transform(self, X, y=None, **kwargs):\n",
    "#         self = self.fit(X, y)\n",
    "#         return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_one_eighteen = [\n",
    "    \"id\",\n",
    "    \"member_id\",\n",
    "    \"funded_amnt\",\n",
    "    \"funded_amnt_inv\",\n",
    "    \"grade\",\n",
    "    \"sub_grade\",\n",
    "    \"emp_title\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `*id` columns are randomly generated so won't help during further analysis. The `*grade` columns overlap with `int_rate`. `emp_title` is a very [high cardinality column](https://en.wikipedia.org/wiki/Cardinality_(SQL_statements)) and requires considerable processing to get something meaningful values/groups. Other columns suffer from [lookahead bias](https://corporatefinanceinstitute.com/resources/knowledge/finance/look-ahead-bias/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second group of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_eighteen_thirtysix = [\n",
    "    \"zip_code\",\n",
    "    \"out_prncp\",\n",
    "    \"out_prncp_inv\",\n",
    "    \"total_pymnt\",\n",
    "    \"total_pymnt_inv\",\n",
    "    \"total_rec_prncp\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`zip_code` overlaps with `addr_state` and is partially [desinsitized](https://patents.google.com/patent/CN106203145A/en) for privacy reasons. Other columns in this group suffer from lookahead bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third group of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_thirtyseven_end = [\n",
    "    \"total_rec_int\",\n",
    "    \"total_rec_late_fee\",\n",
    "    \"recoveries\",\n",
    "    \"collection_recovery_fee\",\n",
    "    \"last_pymnt_amnt\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns in this group suffer from lookahead bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined lists of columns to be dropped, we'll use a pipeline to drop them below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"nan\", DFNanThresholdColumnDropper(nan_threshold)),\n",
    "        (\"nouse\", DFColumnDropper(non_useful_cols)),\n",
    "        (\"dtime\", DFColumnDropper(datetime_cols)),\n",
    "        (\"c1\", DFColumnDropper(cols_one_eighteen)),\n",
    "        (\"c2\", DFColumnDropper(cols_eighteen_thirtysix)),\n",
    "        (\"c3\", DFColumnDropper(cols_thirtyseven_end)),\n",
    "    ]\n",
    ")\n",
    "loans_2007 = pipe.fit_transform(loans_2007)\n",
    "loans_2007.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize distribution of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now examine the class distribution of loan status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_splines(ax: plt.axis) -> plt.axis:\n",
    "    ax.spines[\"left\"].set_edgecolor(\"black\")\n",
    "    ax.spines[\"left\"].set_linewidth(2)\n",
    "    ax.spines[\"bottom\"].set_edgecolor(\"black\")\n",
    "    ax.spines[\"bottom\"].set_linewidth(2)\n",
    "    ax.spines[\"top\"].set_edgecolor(\"lightgrey\")\n",
    "    ax.spines[\"top\"].set_linewidth(1)\n",
    "    ax.spines[\"right\"].set_edgecolor(\"lightgrey\")\n",
    "    ax.spines[\"right\"].set_linewidth(1)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "loans_2007[\"loan_status\"].value_counts().to_frame().sort_values(\n",
    "    by=[\"loan_status\"], ascending=True\n",
    ").plot(ax=ax, kind=\"barh\", zorder=3)\n",
    "ax.get_legend().remove()\n",
    "ax.grid(which=\"both\", axis=\"both\", color=\"lightgrey\", zorder=0)\n",
    "ax.set_title(\"Loan Status\", loc=\"left\", fontweight=\"bold\")\n",
    "_ = customize_splines(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're only looking for binary classification, predicting if a loan is either paid off or not, we'll filter out other entries in the `loan_status` (i.e. the labels) column. By doing this, we will not consider loans that are currently active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DFColumnFilterList(TransformerMixin):\n",
    "#     def __init__(self, column_name, column_values):\n",
    "#         self.column_name = column_name\n",
    "#         self.column_values = column_values\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         # assumes X is a DataFrame\n",
    "#         # return X[pd.DataFrame(X[self.column_name].tolist()).isin(self.column_values).any(1)]\n",
    "#         return X.loc[X[self.column_name].isin(self.column_values)]\n",
    "\n",
    "#     def fit_transform(self, X, y=None, **kwargs):\n",
    "#         self = self.fit(X, y)\n",
    "#         return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_status = [\"Fully Paid\", \"Charged Off\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"filter\", DFColumnFilterList(\"loan_status\", loan_status)),\n",
    "    ]\n",
    ")\n",
    "loans_20072 = pipe.fit_transform(loans_2007)\n",
    "loans_20072.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_20071 = loans_2007[\n",
    "    (loans_2007[\"loan_status\"] == \"Fully Paid\")\n",
    "    | (loans_2007[\"loan_status\"] == \"Charged Off\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert loans_20071.equals(loans_20072)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we'll show the class balance with red being `Charged Off` (not paid on time) and green being `Fully Paid` (paid on time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sns.countplot(x=\"loan_status\", data=loans_20071, ax=axs[0], palette=[\"red\", \"green\"])\n",
    "axs[0].set_title(\"Frequency of each Loan Status\")\n",
    "axs[0].set_ylabel(None)\n",
    "axs[0].set_xlabel(None)\n",
    "loans_20071.loan_status.value_counts().plot(\n",
    "    x=None, y=None, kind=\"pie\", ax=axs[1], autopct=\"%1.2f%%\", colors=[\"green\", \"red\"]\n",
    ")\n",
    "axs[1].set_title(\"Percentage of each Loan status\")\n",
    "axs[1].set_ylabel(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, we'll need to convert these labels to numeric values so we'll make this replacement here with `0` being mapped to `Charged Off` and `1` to `Fully Paid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DFColumnMapper(TransformerMixin):\n",
    "#     def __init__(self, mapping_dict):\n",
    "#         self.mapping_dict = mapping_dict\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         # assumes X is a DataFrame\n",
    "#         return X.replace(self.mapping_dict)\n",
    "\n",
    "#     def fit_transform(self, X, y=None, **kwargs):\n",
    "#         self = self.fit(X, y)\n",
    "#         return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dictionary = {\"loan_status\": {\"Fully Paid\": 1, \"Charged Off\": 0}}\n",
    "loans_200711 = loans_20071.replace(mapping_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"colmap\", DFColumnMapper(mapping_dictionary)),\n",
    "    ]\n",
    ")\n",
    "loans_200722 = pipe.fit_transform(loans_20071)\n",
    "assert loans_200722.equals(loans_200711)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns with infrequently occurring values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll remove categorical columns from the data with a single unique value, since these won't be useful to a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loans_200711 = loans_200711.loc[:, loans_200711.apply(pd.Series.nunique) != 1]\n",
    "single_value_columns = []\n",
    "for col in loans_200711:\n",
    "    non_null = loans_200711[col].dropna()\n",
    "    unique_non_null = non_null.unique()\n",
    "    num_true_unique = len(unique_non_null)\n",
    "    if num_true_unique == 1:\n",
    "        single_value_columns.append(col)\n",
    "loans_2007111 = loans_200711.drop(single_value_columns, axis=1)\n",
    "single_value_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the class method `.unique()` was used to count the number of unique values in a column but, missing values in that column, had to be dropped first since `.unique()` also counts missing values as unique values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll drop columns where there are more than one, but fewer than five, unique values. We've assumed here that an infrequency threshold of five is good enough, but this threshold can be tweaked later if deemed necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in loans_2007111.columns:\n",
    "    if len(loans_2007111[col].unique()) < 4:\n",
    "        display(loans_2007111[col].value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pymnt_plan` column has a single occurrence of `'y'` so it can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_or_less_value_columns = [\"pymnt_plan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_20071111 = loans_2007111.drop(\n",
    "    columns=four_or_less_value_columns, axis=1, errors=\"ignore\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DFNonUniqueValColDropper(TransformerMixin):\n",
    "#     def __init__(self, num_non_unique_vals):\n",
    "#         self.num_non_unique_vals = num_non_unique_vals\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         # assumes X is a DataFrame\n",
    "#         X = X.loc[:, X.apply(pd.Series.nunique) > self.num_non_unique_vals]\n",
    "#         return X\n",
    "\n",
    "#     def fit_transform(self, X, y=None, **kwargs):\n",
    "#         self = self.fit(X, y)\n",
    "#         return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"onevals\", DFNonUniqueValColDropper(1)),\n",
    "        (\"fourvals\", DFColumnDropper(four_or_less_value_columns)),\n",
    "    ]\n",
    ")\n",
    "loans_2007222 = pipe.fit_transform(loans_200722)\n",
    "assert loans_20071111.equals(loans_2007222)\n",
    "display(loans_2007222.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify pipeline-based and manual methods of feature reduction agree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll re-load the raw data and verify that the manual and pipeline-based approaches to dropping, filtering and replacing values in columns agree with eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloud_storage == \"yes\":\n",
    "    az_storage_container_name = \"myconedesx7\"\n",
    "    conn_str = (\n",
    "        \"DefaultEndpointsProtocol=https;\"\n",
    "        f\"AccountName={os.getenv('AZURE_STORAGE_ACCOUNT')};\"\n",
    "        f\"AccountKey={os.getenv('AZURE_STORAGE_KEY')};\"\n",
    "        f\"EndpointSuffix={os.getenv('ENDPOINT_SUFFIX')}\"\n",
    "    )\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(conn_str=conn_str)\n",
    "\n",
    "    blobstrings = {}\n",
    "    for blob_name in [\"blobedesz38\"]:\n",
    "        blob_client = blob_service_client.get_blob_client(\n",
    "            container=az_storage_container_name, blob=blob_name\n",
    "        )\n",
    "        blobstring = blob_client.download_blob().content_as_text()\n",
    "    loans_2007 = pd.read_csv(StringIO(blobstring), skiprows=1, low_memory=False)\n",
    "else:\n",
    "    loans_2007 = pd.read_csv(raw_data_path, skiprows=1, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aside 33% as test data\n",
    "loans_2007, _ = train_test_split(loans_2007, test_size=0.33, random_state=4321)\n",
    "loans_2007 = loans_2007.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"nan\", DFNanThresholdColumnDropper(nan_threshold)),\n",
    "        (\"nouse\", DFColumnDropper(non_useful_cols)),\n",
    "        (\"dtime\", DFColumnDropper(datetime_cols)),\n",
    "        (\"c1\", DFColumnDropper(cols_one_eighteen)),\n",
    "        (\"c2\", DFColumnDropper(cols_eighteen_thirtysix)),\n",
    "        (\"c3\", DFColumnDropper(cols_thirtyseven_end)),\n",
    "        (\n",
    "            \"mapstatus\",\n",
    "            DFColumnFilterList(\"loan_status\", loan_status),\n",
    "        ),\n",
    "        (\"colmap\", DFColumnMapper(mapping_dictionary)),\n",
    "        (\"onevals\", DFNonUniqueValColDropper(1)),\n",
    "        (\"fourvals\", DFColumnDropper(four_or_less_value_columns)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007_pipe_transformed = pipe.fit_transform(loans_2007)\n",
    "print(loans_2007_pipe_transformed.shape)\n",
    "display(loans_2007_pipe_transformed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now verify that both approaches produce the same filtered dataset, for the next phase of processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert loans_2007_pipe_transformed.equals(loans_2007222)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
